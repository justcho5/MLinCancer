{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:2', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:3', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "tf.config.set_visible_devices(physical_devices[0], 'GPU')\n",
    "logical_devices = tf.config.list_logical_devices('GPU')\n",
    "# Logical device was not created for first GPU\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "tc_path = './type-class'\n",
    "nt_path = './normal-tumor'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Use the Type Classifier to classify the Tumor samples from the NT data set.   Using the type IDs from the Type classifier output for the tumor samples create labelled tumor data that you can use to add to the training/testing data for the Type Classifier.  Retrain the Type classifier on the expanded set of data and report on the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My approach is to first speed up and potentially improve the original type classifier. I decided to retrain the original classifier and use only the coding gene data. This allowed significant speed-up. Then I retrain the classifier on the expanded data set and report the results at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I use just the coding genes as features for all problems\n",
    "nt_coding = pd.read_csv('./nt.coding.csv')\n",
    "tc_coding = pd.read_csv('./type.coding.csv')\n",
    "# nt_all = pd.read_csv('./nt.all.csv')\n",
    "# tc_all = pd.read_csv('./type.all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.models import Sequential, Model, model_from_json, model_from_yaml\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau \n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df,n_classes):\n",
    "        '''Load, preprocess, and split data'''\n",
    "        X_train, X_test, y_train, y_test = train_test_split(df.iloc[:,1:].astype('float32'), df.Type.astype('int'), test_size=0.2, random_state=11)\n",
    "\n",
    "        Y_train = tf.keras.utils.to_categorical(y_train,n_classes)\n",
    "        Y_test = tf.keras.utils.to_categorical(y_test,n_classes)\n",
    "              \n",
    "        scaler = MaxAbsScaler()\n",
    "        mat = np.concatenate((X_train, X_test), axis=0)\n",
    "        mat = scaler.fit_transform(mat)\n",
    "        \n",
    "        X_train = mat[:X_train.shape[0], :]\n",
    "        X_test = mat[X_train.shape[0]:, :]\n",
    "\n",
    "        x_train_len = X_train.shape[1]\n",
    "\n",
    "        # this reshaping is critical for the Conv1D to work\n",
    "        X_train = np.expand_dims(X_train, axis=2)\n",
    "        X_test = np.expand_dims(X_test, axis=2)\n",
    "        \n",
    "        return X_train, Y_train, X_test, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 100\n",
    "BATCH = 32\n",
    "CLASSES = 36\n",
    "\n",
    "PL = 19562   # 1 + 60483 these are the width of the RNAseq datasets\n",
    "P     = 19561   # 60483\n",
    "DR    = 0.1 \n",
    "\n",
    "def build_model(n_classes):\n",
    "    '''Builds the model.'''\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=20, strides=1, padding='valid', input_shape=(P, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=5))\n",
    "    model.add(Conv1D(filters=64, kernel_size=10, strides=1, padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling1D(pool_size=10))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(200))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(20))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(n_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=SGD(),\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, Y_train, X_test, Y_test, name):\n",
    "    '''Trains the given model'''\n",
    "    early = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='max',\n",
    "        baseline=None, restore_best_weights=True\n",
    "    )\n",
    "    csv_logger = CSVLogger(f'{name}.training.log')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, verbose=1, mode='auto', min_delta=0.0001, cooldown=0, min_lr=0)\n",
    "\n",
    "    history = model.fit(X_train, Y_train,\n",
    "                        batch_size=BATCH, \n",
    "                        epochs=EPOCH,\n",
    "                        verbose=1, \n",
    "                        validation_data=(X_test, Y_test),\n",
    "                        callbacks = [early, csv_logger, reduce_lr])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, Y_test):\n",
    "    '''Evaluates the model.'''\n",
    "    from sklearn.metrics import f1_score\n",
    "\n",
    "    ytrue = np.argmax(Y_test, axis=-1)\n",
    "    ypred = np.argmax(model.predict(X_test), axis=-1)\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    print('Test AUC:', score[2])\n",
    "    print('Test weighted F1 score:', f1_score(ytrue, ypred, average='weighted'))\n",
    "\n",
    "\n",
    "    print('Confusion Matrix:\\n', tf.math.confusion_matrix(\n",
    "        ytrue, ypred, weights=None, dtype=tf.dtypes.int32,\n",
    "        name=None\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4320, 19561, 1)\n",
      "X_test shape: (1080, 19561, 1)\n",
      "Y_train shape: (4320, 36)\n",
      "Y_test shape: (1080, 36)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 19542, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 19542, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 3908, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3899, 64)          41024     \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 3899, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 389, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 24896)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200)               4979400   \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 36)                756       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 36)                0         \n",
      "=================================================================\n",
      "Total params: 5,026,544\n",
      "Trainable params: 5,026,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 3.4083 - accuracy: 0.0574 - auc: 0.6761 - val_loss: 3.2281 - val_accuracy: 0.0565 - val_auc: 0.7503\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 3.1419 - accuracy: 0.0512 - auc: 0.7475 - val_loss: 2.9654 - val_accuracy: 0.0509 - val_auc: 0.7653\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 3.0208 - accuracy: 0.0546 - auc: 0.7572 - val_loss: 2.9247 - val_accuracy: 0.0556 - val_auc: 0.7607\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 2.9875 - accuracy: 0.0556 - auc: 0.7599 - val_loss: 2.9054 - val_accuracy: 0.0583 - val_auc: 0.7648\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 2.9634 - accuracy: 0.0581 - auc: 0.7637 - val_loss: 2.9081 - val_accuracy: 0.1093 - val_auc: 0.7618\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 2.9455 - accuracy: 0.0662 - auc: 0.7630 - val_loss: 2.8987 - val_accuracy: 0.0796 - val_auc: 0.7678\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.9363 - accuracy: 0.0611 - auc: 0.7624 - val_loss: 2.8934 - val_accuracy: 0.0472 - val_auc: 0.7694\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.9152 - accuracy: 0.0769 - auc: 0.7700 - val_loss: 2.8769 - val_accuracy: 0.0676 - val_auc: 0.7913\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.9123 - accuracy: 0.0769 - auc: 0.7704 - val_loss: 2.8819 - val_accuracy: 0.1269 - val_auc: 0.7731\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.8986 - accuracy: 0.0819 - auc: 0.7758 - val_loss: 2.8674 - val_accuracy: 0.0935 - val_auc: 0.8046\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.8854 - accuracy: 0.0900 - auc: 0.7819 - val_loss: 2.8647 - val_accuracy: 0.1037 - val_auc: 0.7812\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.8648 - accuracy: 0.0926 - auc: 0.7895 - val_loss: 2.8516 - val_accuracy: 0.0741 - val_auc: 0.7985\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.8384 - accuracy: 0.1065 - auc: 0.7982 - val_loss: 2.7984 - val_accuracy: 0.1269 - val_auc: 0.8249\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.7976 - accuracy: 0.1176 - auc: 0.8121 - val_loss: 2.7473 - val_accuracy: 0.0880 - val_auc: 0.8254\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.7330 - accuracy: 0.1366 - auc: 0.8302 - val_loss: 2.6673 - val_accuracy: 0.2435 - val_auc: 0.8864\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.6540 - accuracy: 0.1586 - auc: 0.8541 - val_loss: 2.5655 - val_accuracy: 0.1472 - val_auc: 0.8908\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.5412 - accuracy: 0.1894 - auc: 0.8787 - val_loss: 2.4241 - val_accuracy: 0.3444 - val_auc: 0.9211\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.4035 - accuracy: 0.2583 - auc: 0.9010 - val_loss: 2.2325 - val_accuracy: 0.4278 - val_auc: 0.9408\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.2110 - accuracy: 0.3352 - auc: 0.9239 - val_loss: 2.0675 - val_accuracy: 0.4481 - val_auc: 0.9480\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.9336 - accuracy: 0.4275 - auc: 0.9455 - val_loss: 1.5798 - val_accuracy: 0.6620 - val_auc: 0.9832\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.6288 - accuracy: 0.5118 - auc: 0.9626 - val_loss: 1.2856 - val_accuracy: 0.7472 - val_auc: 0.9897\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.2916 - accuracy: 0.6148 - auc: 0.9778 - val_loss: 0.9135 - val_accuracy: 0.8398 - val_auc: 0.9939\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.0376 - accuracy: 0.6907 - auc: 0.9851 - val_loss: 0.7150 - val_accuracy: 0.8389 - val_auc: 0.9944\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.8395 - accuracy: 0.7553 - auc: 0.9900 - val_loss: 0.6559 - val_accuracy: 0.8037 - val_auc: 0.9944\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.6778 - accuracy: 0.7963 - auc: 0.9932 - val_loss: 0.4117 - val_accuracy: 0.9250 - val_auc: 0.9975\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.5937 - accuracy: 0.8155 - auc: 0.9944 - val_loss: 0.3371 - val_accuracy: 0.9213 - val_auc: 0.9983\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.4927 - accuracy: 0.8539 - auc: 0.9958 - val_loss: 0.2782 - val_accuracy: 0.9278 - val_auc: 0.9977\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.4182 - accuracy: 0.8685 - auc: 0.9972 - val_loss: 0.2396 - val_accuracy: 0.9389 - val_auc: 0.9979\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.3773 - accuracy: 0.8861 - auc: 0.9973 - val_loss: 0.2152 - val_accuracy: 0.9444 - val_auc: 0.9980\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.3244 - accuracy: 0.8965 - auc: 0.9981 - val_loss: 0.2055 - val_accuracy: 0.9491 - val_auc: 0.9986\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.3122 - accuracy: 0.9021 - auc: 0.9980 - val_loss: 0.1705 - val_accuracy: 0.9519 - val_auc: 0.9987\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2714 - accuracy: 0.9167 - auc: 0.9983 - val_loss: 0.1760 - val_accuracy: 0.9528 - val_auc: 0.9982\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2365 - accuracy: 0.9287 - auc: 0.9990 - val_loss: 0.1547 - val_accuracy: 0.9537 - val_auc: 0.9987\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2305 - accuracy: 0.9259 - auc: 0.9992 - val_loss: 0.1383 - val_accuracy: 0.9546 - val_auc: 0.9988\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2219 - accuracy: 0.9319 - auc: 0.9991 - val_loss: 0.1415 - val_accuracy: 0.9528 - val_auc: 0.9988\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1840 - accuracy: 0.9419 - auc: 0.9992 - val_loss: 0.1280 - val_accuracy: 0.9657 - val_auc: 0.9989\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1846 - accuracy: 0.9461 - auc: 0.9991 - val_loss: 0.1246 - val_accuracy: 0.9574 - val_auc: 0.9989\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1568 - accuracy: 0.9519 - auc: 0.9994 - val_loss: 0.1399 - val_accuracy: 0.9574 - val_auc: 0.9984\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1590 - accuracy: 0.9481 - auc: 0.9996 - val_loss: 0.1161 - val_accuracy: 0.9667 - val_auc: 0.9984\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1468 - accuracy: 0.9537 - auc: 0.9997 - val_loss: 0.1280 - val_accuracy: 0.9583 - val_auc: 0.9984\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1363 - accuracy: 0.9569 - auc: 0.9995 - val_loss: 0.1085 - val_accuracy: 0.9694 - val_auc: 0.9984\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1293 - accuracy: 0.9604 - auc: 0.9997 - val_loss: 0.1072 - val_accuracy: 0.9704 - val_auc: 0.9989\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1117 - accuracy: 0.9664 - auc: 0.9998 - val_loss: 0.1175 - val_accuracy: 0.9639 - val_auc: 0.9989\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1116 - accuracy: 0.9685 - auc: 0.9995 - val_loss: 0.1225 - val_accuracy: 0.9630 - val_auc: 0.9984\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0985 - accuracy: 0.9715 - auc: 0.9999 - val_loss: 0.1081 - val_accuracy: 0.9648 - val_auc: 0.9989\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0945 - accuracy: 0.9701 - auc: 0.9997 - val_loss: 0.1159 - val_accuracy: 0.9676 - val_auc: 0.9980\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0944 - accuracy: 0.9729 - auc: 0.9998 - val_loss: 0.1149 - val_accuracy: 0.9630 - val_auc: 0.9980\n",
      "Epoch 48/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.0795 - accuracy: 0.9773 - auc: 0.9998 - val_loss: 0.1039 - val_accuracy: 0.9639 - val_auc: 0.9989\n",
      "Epoch 49/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0786 - accuracy: 0.9748 - auc: 0.9999 - val_loss: 0.0957 - val_accuracy: 0.9648 - val_auc: 0.9989\n",
      "Epoch 50/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0766 - accuracy: 0.9755 - auc: 0.9999 - val_loss: 0.1039 - val_accuracy: 0.9676 - val_auc: 0.9985\n",
      "Epoch 51/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0763 - accuracy: 0.9764 - auc: 0.9999 - val_loss: 0.1091 - val_accuracy: 0.9620 - val_auc: 0.9980\n",
      "Epoch 52/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0715 - accuracy: 0.9785 - auc: 0.9998 - val_loss: 0.1070 - val_accuracy: 0.9611 - val_auc: 0.9989\n",
      "Epoch 53/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0713 - accuracy: 0.9803 - auc: 0.9999 - val_loss: 0.1006 - val_accuracy: 0.9667 - val_auc: 0.9980\n",
      "Epoch 54/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0646 - accuracy: 0.9817 - auc: 0.9999 - val_loss: 0.1025 - val_accuracy: 0.9685 - val_auc: 0.9985\n",
      "Epoch 55/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0582 - accuracy: 0.9824 - auc: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9593 - val_auc: 0.9980\n",
      "Epoch 56/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0583 - accuracy: 0.9838 - auc: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9694 - val_auc: 0.9989\n",
      "Epoch 57/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0590 - accuracy: 0.9817 - auc: 1.0000 - val_loss: 0.0935 - val_accuracy: 0.9667 - val_auc: 0.9985\n",
      "Epoch 58/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0561 - accuracy: 0.9824 - auc: 1.0000 - val_loss: 0.0973 - val_accuracy: 0.9676 - val_auc: 0.9985\n",
      "Epoch 59/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0505 - accuracy: 0.9859 - auc: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9657 - val_auc: 0.9980\n",
      "Epoch 60/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0476 - accuracy: 0.9866 - auc: 1.0000 - val_loss: 0.0926 - val_accuracy: 0.9722 - val_auc: 0.9990\n",
      "Epoch 61/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0484 - accuracy: 0.9829 - auc: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9694 - val_auc: 0.9980\n",
      "Epoch 62/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0363 - accuracy: 0.9894 - auc: 1.0000 - val_loss: 0.1371 - val_accuracy: 0.9630 - val_auc: 0.9966\n",
      "Epoch 63/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0406 - accuracy: 0.9884 - auc: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9685 - val_auc: 0.9985\n",
      "Epoch 64/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0408 - accuracy: 0.9866 - auc: 1.0000 - val_loss: 0.1027 - val_accuracy: 0.9620 - val_auc: 0.9985\n",
      "Epoch 65/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.0398 - accuracy: 0.9887 - auc: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9704 - val_auc: 0.9980\n",
      "Epoch 66/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0415 - accuracy: 0.9877 - auc: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9657 - val_auc: 0.9980\n",
      "Epoch 67/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0391 - accuracy: 0.9900 - auc: 1.0000 - val_loss: 0.1043 - val_accuracy: 0.9704 - val_auc: 0.9980\n",
      "Epoch 68/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.0322 - accuracy: 0.9933 - auc: 0.9999 - val_loss: 0.1018 - val_accuracy: 0.9667 - val_auc: 0.9976\n",
      "Epoch 69/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0308 - accuracy: 0.9905 - auc: 1.0000 - val_loss: 0.1085 - val_accuracy: 0.9667 - val_auc: 0.9976\n",
      "Epoch 70/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0345 - accuracy: 0.9903 - auc: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9667 - val_auc: 0.9980\n",
      "Epoch 71/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0263 - accuracy: 0.9937 - auc: 1.0000 - val_loss: 0.1031 - val_accuracy: 0.9713 - val_auc: 0.9980\n",
      "Epoch 72/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0324 - accuracy: 0.9907 - auc: 1.0000 - val_loss: 0.0906 - val_accuracy: 0.9722 - val_auc: 0.9980\n",
      "Epoch 73/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0309 - accuracy: 0.9907 - auc: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9657 - val_auc: 0.9980\n",
      "Epoch 74/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0273 - accuracy: 0.9935 - auc: 1.0000 - val_loss: 0.1155 - val_accuracy: 0.9667 - val_auc: 0.9985\n",
      "Epoch 75/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0286 - accuracy: 0.9914 - auc: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9676 - val_auc: 0.9966\n",
      "Epoch 76/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0250 - accuracy: 0.9954 - auc: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9731 - val_auc: 0.9976\n",
      "Epoch 77/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0212 - accuracy: 0.9956 - auc: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9685 - val_auc: 0.9971\n",
      "Epoch 78/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0248 - accuracy: 0.9937 - auc: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9676 - val_auc: 0.9966\n",
      "Epoch 79/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0257 - accuracy: 0.9931 - auc: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9667 - val_auc: 0.9985\n",
      "Epoch 80/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0217 - accuracy: 0.9942 - auc: 1.0000 - val_loss: 0.1288 - val_accuracy: 0.9639 - val_auc: 0.9952\n",
      "Epoch 81/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0249 - accuracy: 0.9926 - auc: 1.0000 - val_loss: 0.0980 - val_accuracy: 0.9694 - val_auc: 0.9985\n",
      "Epoch 82/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0239 - accuracy: 0.9942 - auc: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9676 - val_auc: 0.9985\n",
      "Epoch 83/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0248 - accuracy: 0.9919 - auc: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9685 - val_auc: 0.9980\n",
      "Epoch 84/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0232 - accuracy: 0.9926 - auc: 0.9999 - val_loss: 0.1085 - val_accuracy: 0.9676 - val_auc: 0.9971\n",
      "Epoch 85/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0212 - accuracy: 0.9937 - auc: 0.9999 - val_loss: 0.1198 - val_accuracy: 0.9667 - val_auc: 0.9971\n",
      "Epoch 86/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0204 - accuracy: 0.9951 - auc: 1.0000 - val_loss: 0.1203 - val_accuracy: 0.9694 - val_auc: 0.9971\n",
      "Epoch 87/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0217 - accuracy: 0.9954 - auc: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9713 - val_auc: 0.9976\n",
      "Epoch 88/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0185 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 0.1013 - val_accuracy: 0.9722 - val_auc: 0.9980\n",
      "Epoch 89/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0166 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9667 - val_auc: 0.9975\n",
      "Epoch 90/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0220 - accuracy: 0.9949 - auc: 1.0000 - val_loss: 0.1159 - val_accuracy: 0.9713 - val_auc: 0.9966\n",
      "Epoch 91/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0212 - accuracy: 0.9944 - auc: 0.9999 - val_loss: 0.1103 - val_accuracy: 0.9694 - val_auc: 0.9966\n",
      "Epoch 92/100\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0180 - accuracy: 0.9937 - auc: 1.0000\n",
      "Epoch 00092: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0180 - accuracy: 0.9937 - auc: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9667 - val_auc: 0.9962\n",
      "Epoch 93/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0161 - accuracy: 0.9963 - auc: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9667 - val_auc: 0.9971\n",
      "Epoch 94/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0130 - accuracy: 0.9972 - auc: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9685 - val_auc: 0.9971\n",
      "Epoch 95/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0137 - accuracy: 0.9968 - auc: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9676 - val_auc: 0.9966\n",
      "Epoch 96/100\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0125 - accuracy: 0.9968 - auc: 1.0000Restoring model weights from the end of the best epoch.\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0125 - accuracy: 0.9968 - auc: 1.0000 - val_loss: 0.1088 - val_accuracy: 0.9676 - val_auc: 0.9971\n",
      "Epoch 00096: early stopping\n",
      "Test score: 0.09894493222236633\n",
      "Test accuracy: 0.9731481671333313\n",
      "Test AUC: 0.9975752234458923\n",
      "Test weighted F1 score: 0.9730614671974545\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 57  0  0  0  0  0  0  0  0  0  0  0  0  0  1  2  0]\n",
      " [ 0  0  0 59  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1 54  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 61  0  0  0  0  1  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 58  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  6 57  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0 59  0  0  0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 69  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 61  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  1  0  0  0 62  0  0  0  0  0  1  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  0 60  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0 62  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0 55  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 60  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0  0  1  0  0  3  0  0 55  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 48]], shape=(19, 19), dtype=int32)\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Build, train and evaluate the initial type classifier\n",
    "X_train, Y_train, X_test, Y_test = load_data(tc_coding, 36)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "model = build_model(CLASSES)\n",
    "model = train_model(model, X_train, Y_train, X_test, Y_test, 'q1a')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "model.save_weights(\"q1a.model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1b:  Retrain the Type classifier on the expanded set of data and report on the results.\n",
    "\n",
    "Here, I extract the tumor data from the NT dataset and then classify the tumor types with the original type classifier (from 1a). I concatenate this data to the original type classifier data and retrain the classifier. I also checked the distribution of types to see how balanced or imbalanced the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_data(X_df):\n",
    "        X_df = X_df.astype(np.float32)\n",
    "        scaler = MaxAbsScaler()\n",
    "        mat = scaler.fit_transform(X_df)\n",
    "        return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Log transform and zero all -inf values\n",
    "# I want to expand the tumor type dataset so I take the nt_coding data and extract just the tumor samples.\n",
    "# The extracted samples are then preprocessed the same as the training samples.\n",
    "X = nt_coding.copy()\n",
    "X.iloc[:,1:] = X.iloc[:,1:].transform(np.log).replace(to_replace = np.NINF, value = 0)\n",
    "X_tumor = X[X.Type == 1].reset_index(drop=True)\n",
    "X_tumor_scaled = scale_data(X_tumor.iloc[:,1:])\n",
    "X_tumor_input = np.expand_dims(X_tumor_scaled, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the predictions and use those as labels for the additional data\n",
    "y_preds = model.predict(X_tumor_input, batch_size = BATCH)\n",
    "X_tumor.Type = np.argmax(y_preds, axis=1)\n",
    "tot = pd.concat([X_tumor, tc_coding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.11</th>\n",
       "      <th>ENSG00000000457.12</th>\n",
       "      <th>ENSG00000000460.15</th>\n",
       "      <th>ENSG00000000938.11</th>\n",
       "      <th>ENSG00000000971.14</th>\n",
       "      <th>ENSG00000001036.12</th>\n",
       "      <th>ENSG00000001084.9</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000269699.4</th>\n",
       "      <th>ENSG00000269711.1</th>\n",
       "      <th>ENSG00000269741.4</th>\n",
       "      <th>ENSG00000269749.1</th>\n",
       "      <th>ENSG00000269755.1</th>\n",
       "      <th>ENSG00000269846.1</th>\n",
       "      <th>ENSG00000269855.2</th>\n",
       "      <th>ENSG00000269858.4</th>\n",
       "      <th>ENSG00000269881.1</th>\n",
       "      <th>ENSG00000269883.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "      <td>11.817720</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.525503</td>\n",
       "      <td>11.231949</td>\n",
       "      <td>10.236058</td>\n",
       "      <td>10.932715</td>\n",
       "      <td>11.683766</td>\n",
       "      <td>13.473662</td>\n",
       "      <td>12.432776</td>\n",
       "      <td>...</td>\n",
       "      <td>5.776606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.852369</td>\n",
       "      <td>6.49404</td>\n",
       "      <td>7.349324</td>\n",
       "      <td>5.387506</td>\n",
       "      <td>9.700025</td>\n",
       "      <td>10.911068</td>\n",
       "      <td>8.523233</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>13.014913</td>\n",
       "      <td>8.370332</td>\n",
       "      <td>13.082076</td>\n",
       "      <td>10.618813</td>\n",
       "      <td>9.832910</td>\n",
       "      <td>12.069463</td>\n",
       "      <td>10.026306</td>\n",
       "      <td>14.546522</td>\n",
       "      <td>13.024953</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.075009</td>\n",
       "      <td>8.157713</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.129652</td>\n",
       "      <td>9.103908</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>13.570081</td>\n",
       "      <td>5.689703</td>\n",
       "      <td>13.063701</td>\n",
       "      <td>11.312691</td>\n",
       "      <td>9.992821</td>\n",
       "      <td>10.637658</td>\n",
       "      <td>12.385566</td>\n",
       "      <td>12.962867</td>\n",
       "      <td>12.088561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.506864</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.390113</td>\n",
       "      <td>5.833760</td>\n",
       "      <td>8.815045</td>\n",
       "      <td>11.145116</td>\n",
       "      <td>7.304479</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>12.420320</td>\n",
       "      <td>8.263382</td>\n",
       "      <td>13.239291</td>\n",
       "      <td>10.555530</td>\n",
       "      <td>9.740280</td>\n",
       "      <td>11.859855</td>\n",
       "      <td>13.454218</td>\n",
       "      <td>13.523871</td>\n",
       "      <td>11.276741</td>\n",
       "      <td>...</td>\n",
       "      <td>5.826125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.515593</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>7.804307</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.505592</td>\n",
       "      <td>8.502792</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>10.991687</td>\n",
       "      <td>7.518864</td>\n",
       "      <td>13.576669</td>\n",
       "      <td>11.257765</td>\n",
       "      <td>10.604674</td>\n",
       "      <td>12.356410</td>\n",
       "      <td>14.241380</td>\n",
       "      <td>13.129423</td>\n",
       "      <td>11.862458</td>\n",
       "      <td>...</td>\n",
       "      <td>6.547944</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>8.274812</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.807924</td>\n",
       "      <td>11.265453</td>\n",
       "      <td>8.209381</td>\n",
       "      <td>6.057508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  ENSG00000000003.13  ENSG00000000005.5  ENSG00000000419.11  \\\n",
       "0    12           11.817720           0.000000           13.525503   \n",
       "1     4           13.014913           8.370332           13.082076   \n",
       "2     5           13.570081           5.689703           13.063701   \n",
       "3     3           12.420320           8.263382           13.239291   \n",
       "4    12           10.991687           7.518864           13.576669   \n",
       "\n",
       "   ENSG00000000457.12  ENSG00000000460.15  ENSG00000000938.11  \\\n",
       "0           11.231949           10.236058           10.932715   \n",
       "1           10.618813            9.832910           12.069463   \n",
       "2           11.312691            9.992821           10.637658   \n",
       "3           10.555530            9.740280           11.859855   \n",
       "4           11.257765           10.604674           12.356410   \n",
       "\n",
       "   ENSG00000000971.14  ENSG00000001036.12  ENSG00000001084.9  ...  \\\n",
       "0           11.683766           13.473662          12.432776  ...   \n",
       "1           10.026306           14.546522          13.024953  ...   \n",
       "2           12.385566           12.962867          12.088561  ...   \n",
       "3           13.454218           13.523871          11.276741  ...   \n",
       "4           14.241380           13.129423          11.862458  ...   \n",
       "\n",
       "   ENSG00000269699.4  ENSG00000269711.1  ENSG00000269741.4  ENSG00000269749.1  \\\n",
       "0           5.776606                0.0           6.852369            6.49404   \n",
       "1           0.000000                0.0           0.000000            0.00000   \n",
       "2           0.000000                0.0           5.506864            0.00000   \n",
       "3           5.826125                0.0           5.515593            0.00000   \n",
       "4           6.547944                0.0           0.000000            0.00000   \n",
       "\n",
       "   ENSG00000269755.1  ENSG00000269846.1  ENSG00000269855.2  ENSG00000269858.4  \\\n",
       "0           7.349324           5.387506           9.700025          10.911068   \n",
       "1           7.075009           8.157713           0.000000          11.129652   \n",
       "2           7.390113           5.833760           8.815045          11.145116   \n",
       "3           7.804307           0.000000           0.000000          11.505592   \n",
       "4           8.274812           0.000000           5.807924          11.265453   \n",
       "\n",
       "   ENSG00000269881.1  ENSG00000269883.1  \n",
       "0           8.523233           0.000000  \n",
       "1           9.103908           0.000000  \n",
       "2           7.304479           0.000000  \n",
       "3           8.502792           0.000000  \n",
       "4           8.209381           6.057508  \n",
       "\n",
       "[5 rows x 19562 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Check the distribution of classes.\n",
    "tot.Type.hist(bins=36)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4880, 19561, 1)\n",
      "X_test shape: (1220, 19561, 1)\n",
      "Y_train shape: (4880, 36)\n",
      "Y_test shape: (1220, 36)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 19542, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 19542, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 3908, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 3899, 64)          41024     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 3899, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 389, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 24896)             0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               4979400   \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 36)                756       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 36)                0         \n",
      "=================================================================\n",
      "Total params: 5,026,544\n",
      "Trainable params: 5,026,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "153/153 [==============================] - 5s 32ms/step - loss: 3.5099 - accuracy: 0.0504 - auc_1: 0.6064 - val_loss: 3.4090 - val_accuracy: 0.0754 - val_auc_1: 0.6984\n",
      "Epoch 2/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 3.2635 - accuracy: 0.0633 - auc_1: 0.7287 - val_loss: 3.0222 - val_accuracy: 0.0508 - val_auc_1: 0.7620\n",
      "Epoch 3/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 3.0092 - accuracy: 0.0627 - auc_1: 0.7588 - val_loss: 2.9141 - val_accuracy: 0.0557 - val_auc_1: 0.7751\n",
      "Epoch 4/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9655 - accuracy: 0.0557 - auc_1: 0.7648 - val_loss: 2.9050 - val_accuracy: 0.0508 - val_auc_1: 0.7697\n",
      "Epoch 5/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9542 - accuracy: 0.0643 - auc_1: 0.7650 - val_loss: 2.9170 - val_accuracy: 0.0623 - val_auc_1: 0.7699\n",
      "Epoch 6/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9491 - accuracy: 0.0656 - auc_1: 0.7658 - val_loss: 2.8929 - val_accuracy: 0.0566 - val_auc_1: 0.7747\n",
      "Epoch 7/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9450 - accuracy: 0.0621 - auc_1: 0.7689 - val_loss: 2.9041 - val_accuracy: 0.0459 - val_auc_1: 0.7727\n",
      "Epoch 8/100\n",
      "153/153 [==============================] - 5s 30ms/step - loss: 2.9413 - accuracy: 0.0678 - auc_1: 0.7702 - val_loss: 2.8917 - val_accuracy: 0.1221 - val_auc_1: 0.7779\n",
      "Epoch 9/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9321 - accuracy: 0.0672 - auc_1: 0.7719 - val_loss: 2.8822 - val_accuracy: 0.0508 - val_auc_1: 0.7796\n",
      "Epoch 10/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9311 - accuracy: 0.0723 - auc_1: 0.7737 - val_loss: 2.8740 - val_accuracy: 0.0836 - val_auc_1: 0.7917\n",
      "Epoch 11/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9203 - accuracy: 0.0766 - auc_1: 0.7784 - val_loss: 2.8784 - val_accuracy: 0.0680 - val_auc_1: 0.7862\n",
      "Epoch 12/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.9102 - accuracy: 0.0750 - auc_1: 0.7847 - val_loss: 2.8593 - val_accuracy: 0.1508 - val_auc_1: 0.8062\n",
      "Epoch 13/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.8953 - accuracy: 0.0932 - auc_1: 0.7930 - val_loss: 2.8500 - val_accuracy: 0.0836 - val_auc_1: 0.8156\n",
      "Epoch 14/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.8735 - accuracy: 0.1076 - auc_1: 0.8027 - val_loss: 2.8244 - val_accuracy: 0.1361 - val_auc_1: 0.8249\n",
      "Epoch 15/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.8403 - accuracy: 0.1230 - auc_1: 0.8174 - val_loss: 2.7868 - val_accuracy: 0.0836 - val_auc_1: 0.8461\n",
      "Epoch 16/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.7771 - accuracy: 0.1588 - auc_1: 0.8396 - val_loss: 2.7054 - val_accuracy: 0.2615 - val_auc_1: 0.8600\n",
      "Epoch 17/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.6584 - accuracy: 0.2010 - auc_1: 0.8680 - val_loss: 2.5239 - val_accuracy: 0.2803 - val_auc_1: 0.9086\n",
      "Epoch 18/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.4671 - accuracy: 0.2621 - auc_1: 0.8944 - val_loss: 2.2898 - val_accuracy: 0.3213 - val_auc_1: 0.9263\n",
      "Epoch 19/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 2.2155 - accuracy: 0.3264 - auc_1: 0.9200 - val_loss: 2.1788 - val_accuracy: 0.2844 - val_auc_1: 0.9334\n",
      "Epoch 20/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 1.9345 - accuracy: 0.4230 - auc_1: 0.9419 - val_loss: 1.7607 - val_accuracy: 0.6352 - val_auc_1: 0.9728\n",
      "Epoch 21/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 1.6196 - accuracy: 0.5250 - auc_1: 0.9610 - val_loss: 1.2110 - val_accuracy: 0.7049 - val_auc_1: 0.9885\n",
      "Epoch 22/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 1.3028 - accuracy: 0.6162 - auc_1: 0.9758 - val_loss: 0.9651 - val_accuracy: 0.7549 - val_auc_1: 0.9910\n",
      "Epoch 23/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 1.0277 - accuracy: 0.7006 - auc_1: 0.9844 - val_loss: 0.6325 - val_accuracy: 0.8656 - val_auc_1: 0.9955\n",
      "Epoch 24/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.8039 - accuracy: 0.7615 - auc_1: 0.9900 - val_loss: 0.4876 - val_accuracy: 0.8705 - val_auc_1: 0.9972\n",
      "Epoch 25/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.5959 - accuracy: 0.8232 - auc_1: 0.9945 - val_loss: 0.3749 - val_accuracy: 0.9025 - val_auc_1: 0.9979\n",
      "Epoch 26/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.5039 - accuracy: 0.8523 - auc_1: 0.9956 - val_loss: 0.4613 - val_accuracy: 0.8738 - val_auc_1: 0.9975\n",
      "Epoch 27/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.4113 - accuracy: 0.8809 - auc_1: 0.9969 - val_loss: 0.2511 - val_accuracy: 0.9426 - val_auc_1: 0.9989\n",
      "Epoch 28/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.3590 - accuracy: 0.8912 - auc_1: 0.9977 - val_loss: 0.1950 - val_accuracy: 0.9475 - val_auc_1: 0.9992\n",
      "Epoch 29/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.3000 - accuracy: 0.9135 - auc_1: 0.9981 - val_loss: 0.3054 - val_accuracy: 0.8902 - val_auc_1: 0.9983\n",
      "Epoch 30/100\n",
      "153/153 [==============================] - 5s 30ms/step - loss: 0.2634 - accuracy: 0.9268 - auc_1: 0.9982 - val_loss: 0.1669 - val_accuracy: 0.9557 - val_auc_1: 0.9988\n",
      "Epoch 31/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.2279 - accuracy: 0.9340 - auc_1: 0.9987 - val_loss: 0.1626 - val_accuracy: 0.9492 - val_auc_1: 0.9996\n",
      "Epoch 32/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.2156 - accuracy: 0.9336 - auc_1: 0.9989 - val_loss: 0.1456 - val_accuracy: 0.9590 - val_auc_1: 0.9989\n",
      "Epoch 33/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1921 - accuracy: 0.9385 - auc_1: 0.9991 - val_loss: 0.1192 - val_accuracy: 0.9615 - val_auc_1: 0.9990\n",
      "Epoch 34/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1656 - accuracy: 0.9531 - auc_1: 0.9992 - val_loss: 0.1504 - val_accuracy: 0.9533 - val_auc_1: 0.9984\n",
      "Epoch 35/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1656 - accuracy: 0.9518 - auc_1: 0.9991 - val_loss: 0.1404 - val_accuracy: 0.9582 - val_auc_1: 0.9985\n",
      "Epoch 36/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1429 - accuracy: 0.9596 - auc_1: 0.9994 - val_loss: 0.1389 - val_accuracy: 0.9566 - val_auc_1: 0.9985\n",
      "Epoch 37/100\n",
      "153/153 [==============================] - 5s 29ms/step - loss: 0.1287 - accuracy: 0.9643 - auc_1: 0.9997 - val_loss: 0.1847 - val_accuracy: 0.9451 - val_auc_1: 0.9971\n",
      "Epoch 38/100\n",
      "153/153 [==============================] - 5s 30ms/step - loss: 0.1228 - accuracy: 0.9621 - auc_1: 0.9996 - val_loss: 0.1375 - val_accuracy: 0.9639 - val_auc_1: 0.9981\n",
      "Epoch 39/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1133 - accuracy: 0.9684 - auc_1: 0.9997 - val_loss: 0.0964 - val_accuracy: 0.9705 - val_auc_1: 0.9991\n",
      "Epoch 40/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1111 - accuracy: 0.9656 - auc_1: 0.9997 - val_loss: 0.1717 - val_accuracy: 0.9484 - val_auc_1: 0.9983\n",
      "Epoch 41/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.1086 - accuracy: 0.9682 - auc_1: 0.9998 - val_loss: 0.1008 - val_accuracy: 0.9648 - val_auc_1: 0.9990\n",
      "Epoch 42/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0951 - accuracy: 0.9711 - auc_1: 0.9999 - val_loss: 0.1267 - val_accuracy: 0.9566 - val_auc_1: 0.9977\n",
      "Epoch 43/100\n",
      "153/153 [==============================] - 5s 29ms/step - loss: 0.0922 - accuracy: 0.9721 - auc_1: 0.9999 - val_loss: 0.1185 - val_accuracy: 0.9697 - val_auc_1: 0.9973\n",
      "Epoch 44/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0831 - accuracy: 0.9738 - auc_1: 0.9998 - val_loss: 0.1643 - val_accuracy: 0.9525 - val_auc_1: 0.9972\n",
      "Epoch 45/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0841 - accuracy: 0.9732 - auc_1: 0.9998 - val_loss: 0.0958 - val_accuracy: 0.9689 - val_auc_1: 0.9987\n",
      "Epoch 46/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0737 - accuracy: 0.9777 - auc_1: 0.9999 - val_loss: 0.0996 - val_accuracy: 0.9738 - val_auc_1: 0.9982\n",
      "Epoch 47/100\n",
      "153/153 [==============================] - 5s 29ms/step - loss: 0.0732 - accuracy: 0.9770 - auc_1: 0.9999 - val_loss: 0.0908 - val_accuracy: 0.9705 - val_auc_1: 0.9987\n",
      "Epoch 48/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0724 - accuracy: 0.9785 - auc_1: 0.9999 - val_loss: 0.1029 - val_accuracy: 0.9656 - val_auc_1: 0.9986\n",
      "Epoch 49/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0589 - accuracy: 0.9842 - auc_1: 0.9999 - val_loss: 0.0963 - val_accuracy: 0.9697 - val_auc_1: 0.9974\n",
      "Epoch 50/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0646 - accuracy: 0.9799 - auc_1: 1.0000 - val_loss: 0.0959 - val_accuracy: 0.9705 - val_auc_1: 0.9982\n",
      "Epoch 51/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0610 - accuracy: 0.9803 - auc_1: 1.0000 - val_loss: 0.0961 - val_accuracy: 0.9746 - val_auc_1: 0.9986\n",
      "Epoch 52/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0593 - accuracy: 0.9822 - auc_1: 0.9997 - val_loss: 0.0939 - val_accuracy: 0.9738 - val_auc_1: 0.9991\n",
      "Epoch 53/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0566 - accuracy: 0.9859 - auc_1: 1.0000 - val_loss: 0.0938 - val_accuracy: 0.9664 - val_auc_1: 0.9978\n",
      "Epoch 54/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0507 - accuracy: 0.9865 - auc_1: 0.9999 - val_loss: 0.0934 - val_accuracy: 0.9730 - val_auc_1: 0.9983\n",
      "Epoch 55/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0487 - accuracy: 0.9875 - auc_1: 0.9999 - val_loss: 0.0977 - val_accuracy: 0.9738 - val_auc_1: 0.9979\n",
      "Epoch 56/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0461 - accuracy: 0.9852 - auc_1: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9672 - val_auc_1: 0.9983\n",
      "Epoch 57/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0365 - accuracy: 0.9891 - auc_1: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9697 - val_auc_1: 0.9987\n",
      "Epoch 58/100\n",
      "153/153 [==============================] - 5s 29ms/step - loss: 0.0471 - accuracy: 0.9855 - auc_1: 1.0000 - val_loss: 0.1555 - val_accuracy: 0.9631 - val_auc_1: 0.9965\n",
      "Epoch 59/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0425 - accuracy: 0.9889 - auc_1: 0.9998 - val_loss: 0.1094 - val_accuracy: 0.9623 - val_auc_1: 0.9978\n",
      "Epoch 60/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0396 - accuracy: 0.9900 - auc_1: 0.9999 - val_loss: 0.1074 - val_accuracy: 0.9721 - val_auc_1: 0.9974\n",
      "Epoch 61/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0406 - accuracy: 0.9887 - auc_1: 1.0000 - val_loss: 0.0977 - val_accuracy: 0.9672 - val_auc_1: 0.9978\n",
      "Epoch 62/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0376 - accuracy: 0.9895 - auc_1: 1.0000 - val_loss: 0.1408 - val_accuracy: 0.9582 - val_auc_1: 0.9969\n",
      "Epoch 63/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0306 - accuracy: 0.9916 - auc_1: 1.0000 - val_loss: 0.0963 - val_accuracy: 0.9689 - val_auc_1: 0.9979\n",
      "Epoch 64/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0291 - accuracy: 0.9930 - auc_1: 1.0000 - val_loss: 0.1151 - val_accuracy: 0.9689 - val_auc_1: 0.9974\n",
      "Epoch 65/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0350 - accuracy: 0.9895 - auc_1: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9680 - val_auc_1: 0.9982\n",
      "Epoch 66/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0315 - accuracy: 0.9918 - auc_1: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9730 - val_auc_1: 0.9974\n",
      "Epoch 67/100\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.0308 - accuracy: 0.9925 - auc_1: 1.0000\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0307 - accuracy: 0.9926 - auc_1: 1.0000 - val_loss: 0.0983 - val_accuracy: 0.9746 - val_auc_1: 0.9987\n",
      "Epoch 68/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0254 - accuracy: 0.9934 - auc_1: 1.0000 - val_loss: 0.0955 - val_accuracy: 0.9689 - val_auc_1: 0.9975\n",
      "Epoch 69/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0230 - accuracy: 0.9939 - auc_1: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9746 - val_auc_1: 0.9979\n",
      "Epoch 70/100\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0214 - accuracy: 0.9957 - auc_1: 1.0000 - val_loss: 0.0981 - val_accuracy: 0.9705 - val_auc_1: 0.9975\n",
      "Epoch 71/100\n",
      "151/153 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9952 - auc_1: 1.0000Restoring model weights from the end of the best epoch.\n",
      "153/153 [==============================] - 4s 29ms/step - loss: 0.0207 - accuracy: 0.9953 - auc_1: 1.0000 - val_loss: 0.0979 - val_accuracy: 0.9713 - val_auc_1: 0.9975\n",
      "Epoch 00071: early stopping\n",
      "Test score: 0.09614527225494385\n",
      "Test accuracy: 0.9745901823043823\n",
      "Test AUC: 0.9986499547958374\n",
      "Test weighted F1 score: 0.9741956503636976\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 43  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 67  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 72  4  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2 60  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 82  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 81  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  0  9 53  0  0  0  1  0  0  0  1  1  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 61  0  0  0  1  0  2  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 66  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 62  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 63  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 84  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 62  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 55  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 62  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 97  0  0]\n",
      " [ 0  0  0  0  0  0  0  1  0  0  0  1  0  0  1  0  0 57  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 62]], shape=(19, 19), dtype=int32)\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Retrain on the expanded dataset.\n",
    "CLASSES=36\n",
    "X_train, Y_train, X_test, Y_test = load_data(tot, 36)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "model = build_model(CLASSES)\n",
    "model = train_model(model, X_train, Y_train, X_test, Y_test, 'q1b')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "model.save_weights(\"q1b.model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: 1 paragraph write up for each part and section, explaining what you did and your critique of the results, comments on problems or difficulties and possible future approaches that might do better\n",
    "\n",
    "For this problem, I retrained the original type classifier using the `tc.coding.csv` data. In order to speed up training (without compromising performance), I adjusted the given architecture, reducing the number of filters used in the convolutional layers, and increasing the max pool size. In addition, I implemented early stopping with a patience of 20. With these adjustments, I achieved a final validation accuracy of 97.5% accuracy, an AUC of 0.999, and a weighted F1 of 0.974. I checked many metrics besides accuracy because accuracy can sometimes not be reflective of performance if the classes are imbalanced. In our case, the classes aren't terribly imbalanced; however, the different metrics give us hope that the performance is good. With the confusion matrix, we can see that some datapoints are incorrectly classified. Along the rows is the true labels and along the columns are the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Using the “normal” samples from the NT dataset add a “normal” type to the Type Classifier training/testing data and retrain the model.  Report on the results (accuracy, confusion matrix etc.).\n",
    "\n",
    "For this problem, I first will extract the normal samples from the NT dataset and relabel them with 36 since the tumor types are 0-35 (although we only have 18 tumor types in the dataset). Then, we concatenate this normal set with the expanded dataset from above. Finally, we will retrain the model with this new data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.11</th>\n",
       "      <th>ENSG00000000457.12</th>\n",
       "      <th>ENSG00000000460.15</th>\n",
       "      <th>ENSG00000000938.11</th>\n",
       "      <th>ENSG00000000971.14</th>\n",
       "      <th>ENSG00000001036.12</th>\n",
       "      <th>ENSG00000001084.9</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000269699.4</th>\n",
       "      <th>ENSG00000269711.1</th>\n",
       "      <th>ENSG00000269741.4</th>\n",
       "      <th>ENSG00000269749.1</th>\n",
       "      <th>ENSG00000269755.1</th>\n",
       "      <th>ENSG00000269846.1</th>\n",
       "      <th>ENSG00000269855.2</th>\n",
       "      <th>ENSG00000269858.4</th>\n",
       "      <th>ENSG00000269881.1</th>\n",
       "      <th>ENSG00000269883.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>11.920159</td>\n",
       "      <td>8.372825</td>\n",
       "      <td>13.478511</td>\n",
       "      <td>10.998672</td>\n",
       "      <td>9.648070</td>\n",
       "      <td>10.759334</td>\n",
       "      <td>12.125389</td>\n",
       "      <td>12.621583</td>\n",
       "      <td>11.527706</td>\n",
       "      <td>...</td>\n",
       "      <td>6.197932</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.617948</td>\n",
       "      <td>6.907444</td>\n",
       "      <td>7.942819</td>\n",
       "      <td>11.291818</td>\n",
       "      <td>8.830148</td>\n",
       "      <td>5.302032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>13.724741</td>\n",
       "      <td>7.752028</td>\n",
       "      <td>13.627373</td>\n",
       "      <td>10.825815</td>\n",
       "      <td>10.324726</td>\n",
       "      <td>11.693486</td>\n",
       "      <td>12.687636</td>\n",
       "      <td>12.358283</td>\n",
       "      <td>12.227883</td>\n",
       "      <td>...</td>\n",
       "      <td>4.989348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.694974</td>\n",
       "      <td>6.805395</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.698860</td>\n",
       "      <td>11.578422</td>\n",
       "      <td>10.923966</td>\n",
       "      <td>6.609963</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>36</td>\n",
       "      <td>12.792911</td>\n",
       "      <td>12.341353</td>\n",
       "      <td>13.089759</td>\n",
       "      <td>11.154427</td>\n",
       "      <td>9.728496</td>\n",
       "      <td>11.244961</td>\n",
       "      <td>13.508452</td>\n",
       "      <td>13.147186</td>\n",
       "      <td>11.591253</td>\n",
       "      <td>...</td>\n",
       "      <td>6.057227</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.189560</td>\n",
       "      <td>5.380444</td>\n",
       "      <td>7.332110</td>\n",
       "      <td>11.045752</td>\n",
       "      <td>8.370989</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>11.307804</td>\n",
       "      <td>5.177901</td>\n",
       "      <td>12.802935</td>\n",
       "      <td>10.728146</td>\n",
       "      <td>9.055277</td>\n",
       "      <td>13.440640</td>\n",
       "      <td>11.874253</td>\n",
       "      <td>13.038852</td>\n",
       "      <td>10.722581</td>\n",
       "      <td>...</td>\n",
       "      <td>5.305594</td>\n",
       "      <td>10.065334</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.428493</td>\n",
       "      <td>6.878311</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.861410</td>\n",
       "      <td>11.549187</td>\n",
       "      <td>7.554817</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>12.653028</td>\n",
       "      <td>7.085127</td>\n",
       "      <td>13.594145</td>\n",
       "      <td>11.071110</td>\n",
       "      <td>9.540186</td>\n",
       "      <td>11.073946</td>\n",
       "      <td>12.480268</td>\n",
       "      <td>13.190543</td>\n",
       "      <td>11.917140</td>\n",
       "      <td>...</td>\n",
       "      <td>7.723645</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.543959</td>\n",
       "      <td>7.686925</td>\n",
       "      <td>7.516866</td>\n",
       "      <td>7.389090</td>\n",
       "      <td>11.316137</td>\n",
       "      <td>8.812381</td>\n",
       "      <td>5.623771</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  ENSG00000000003.13  ENSG00000000005.5  ENSG00000000419.11  \\\n",
       "0    36           11.920159           8.372825           13.478511   \n",
       "1    36           13.724741           7.752028           13.627373   \n",
       "2    36           12.792911          12.341353           13.089759   \n",
       "3    36           11.307804           5.177901           12.802935   \n",
       "4    36           12.653028           7.085127           13.594145   \n",
       "\n",
       "   ENSG00000000457.12  ENSG00000000460.15  ENSG00000000938.11  \\\n",
       "0           10.998672            9.648070           10.759334   \n",
       "1           10.825815           10.324726           11.693486   \n",
       "2           11.154427            9.728496           11.244961   \n",
       "3           10.728146            9.055277           13.440640   \n",
       "4           11.071110            9.540186           11.073946   \n",
       "\n",
       "   ENSG00000000971.14  ENSG00000001036.12  ENSG00000001084.9  ...  \\\n",
       "0           12.125389           12.621583          11.527706  ...   \n",
       "1           12.687636           12.358283          12.227883  ...   \n",
       "2           13.508452           13.147186          11.591253  ...   \n",
       "3           11.874253           13.038852          10.722581  ...   \n",
       "4           12.480268           13.190543          11.917140  ...   \n",
       "\n",
       "   ENSG00000269699.4  ENSG00000269711.1  ENSG00000269741.4  ENSG00000269749.1  \\\n",
       "0           6.197932           0.000000           0.000000           0.000000   \n",
       "1           4.989348           0.000000          10.694974           6.805395   \n",
       "2           6.057227           0.000000           0.000000           0.000000   \n",
       "3           5.305594          10.065334           0.000000           6.428493   \n",
       "4           7.723645           0.000000           0.000000           6.543959   \n",
       "\n",
       "   ENSG00000269755.1  ENSG00000269846.1  ENSG00000269855.2  ENSG00000269858.4  \\\n",
       "0           8.617948           6.907444           7.942819          11.291818   \n",
       "1           0.000000           5.698860          11.578422          10.923966   \n",
       "2           8.189560           5.380444           7.332110          11.045752   \n",
       "3           6.878311           0.000000           7.861410          11.549187   \n",
       "4           7.686925           7.516866           7.389090          11.316137   \n",
       "\n",
       "   ENSG00000269881.1  ENSG00000269883.1  \n",
       "0           8.830148           5.302032  \n",
       "1           6.609963           0.000000  \n",
       "2           8.370989           0.000000  \n",
       "3           7.554817           0.000000  \n",
       "4           8.812381           5.623771  \n",
       "\n",
       "[5 rows x 19562 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the normal samples from the NT dataset and add a normal type to the type classifier data. \n",
    "# There are 36 different tumor types (although the data only has 18 types), \n",
    "# so the normal type will be labeled as 36 in the new data\n",
    "\n",
    "normal = nt_coding.copy()\n",
    "normal.iloc[:,1:] = normal.iloc[:,1:].transform(np.log).replace(to_replace = np.NINF, value = 0)\n",
    "normal=normal[normal.Type == 0].reset_index(drop=True)\n",
    "normal.loc[:,'Type'] = [36]*normal.shape[0]\n",
    "normal.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concatenate the type classifier expanded dataset from problem 1b with the normal samples from the NT data\n",
    "# We again check the class distribution\n",
    "with_normal = pd.concat([tot, normal])\n",
    "with_normal.Type.hist(bins=37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, I checked the distribution of classes. We see a big gap between 18 and 36 because those are the types that don't exist in our dataset. This will have no impact on performance or model training. We notice from the histogram that there are about 2 times more samples in normal than any of the other classes. This is not drastically imbalanced; however, we can still analyze the **weighted** F1 score which is better for potentially imbalanced dataset since it will consider the number of instances per label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (5440, 19561, 1)\n",
      "X_test shape: (1360, 19561, 1)\n",
      "Y_train shape: (5440, 37)\n",
      "Y_test shape: (1360, 37)\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_4 (Conv1D)            (None, 19542, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 19542, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 3908, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 3899, 64)          41024     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 3899, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 389, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 24896)             0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 200)               4979400   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 37)                777       \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 5,026,565\n",
      "Trainable params: 5,026,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 3.3754 - accuracy: 0.0494 - auc_2: 0.7002 - val_loss: 3.0763 - val_accuracy: 0.1029 - val_auc_2: 0.7649\n",
      "Epoch 2/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 3.1020 - accuracy: 0.0748 - auc_2: 0.7556 - val_loss: 2.9826 - val_accuracy: 0.1029 - val_auc_2: 0.7656\n",
      "Epoch 3/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 3.0473 - accuracy: 0.0831 - auc_2: 0.7594 - val_loss: 2.9651 - val_accuracy: 0.1029 - val_auc_2: 0.7768\n",
      "Epoch 4/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 3.0107 - accuracy: 0.0895 - auc_2: 0.7645 - val_loss: 2.9478 - val_accuracy: 0.1029 - val_auc_2: 0.7727\n",
      "Epoch 5/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.9941 - accuracy: 0.0829 - auc_2: 0.7670 - val_loss: 2.9436 - val_accuracy: 0.1029 - val_auc_2: 0.7786\n",
      "Epoch 6/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.9719 - accuracy: 0.0972 - auc_2: 0.7699 - val_loss: 2.9228 - val_accuracy: 0.1353 - val_auc_2: 0.7796\n",
      "Epoch 7/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.9509 - accuracy: 0.1046 - auc_2: 0.7754 - val_loss: 2.9103 - val_accuracy: 0.1441 - val_auc_2: 0.7981\n",
      "Epoch 8/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.9239 - accuracy: 0.1239 - auc_2: 0.7816 - val_loss: 2.8685 - val_accuracy: 0.1029 - val_auc_2: 0.7907\n",
      "Epoch 9/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.8525 - accuracy: 0.1460 - auc_2: 0.7966 - val_loss: 2.7488 - val_accuracy: 0.2044 - val_auc_2: 0.8246\n",
      "Epoch 10/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.7841 - accuracy: 0.1524 - auc_2: 0.8128 - val_loss: 2.7144 - val_accuracy: 0.1596 - val_auc_2: 0.8398\n",
      "Epoch 11/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.7443 - accuracy: 0.1675 - auc_2: 0.8248 - val_loss: 2.6821 - val_accuracy: 0.1500 - val_auc_2: 0.8513\n",
      "Epoch 12/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.7108 - accuracy: 0.1853 - auc_2: 0.8363 - val_loss: 2.6683 - val_accuracy: 0.2346 - val_auc_2: 0.8508\n",
      "Epoch 13/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.6731 - accuracy: 0.1952 - auc_2: 0.8488 - val_loss: 2.5950 - val_accuracy: 0.1838 - val_auc_2: 0.8830\n",
      "Epoch 14/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.5987 - accuracy: 0.2287 - auc_2: 0.8686 - val_loss: 2.4767 - val_accuracy: 0.2882 - val_auc_2: 0.9178\n",
      "Epoch 15/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.4655 - accuracy: 0.2693 - auc_2: 0.8942 - val_loss: 2.3428 - val_accuracy: 0.4375 - val_auc_2: 0.9445\n",
      "Epoch 16/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 2.2228 - accuracy: 0.3476 - auc_2: 0.9228 - val_loss: 2.0297 - val_accuracy: 0.3897 - val_auc_2: 0.9488\n",
      "Epoch 17/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 1.8762 - accuracy: 0.4450 - auc_2: 0.9497 - val_loss: 1.5459 - val_accuracy: 0.6390 - val_auc_2: 0.9761\n",
      "Epoch 18/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 1.5356 - accuracy: 0.5278 - auc_2: 0.9680 - val_loss: 1.1554 - val_accuracy: 0.7007 - val_auc_2: 0.9862\n",
      "Epoch 19/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 1.2215 - accuracy: 0.6224 - auc_2: 0.9804 - val_loss: 0.8921 - val_accuracy: 0.8022 - val_auc_2: 0.9917\n",
      "Epoch 20/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.9432 - accuracy: 0.7072 - auc_2: 0.9882 - val_loss: 0.5900 - val_accuracy: 0.8949 - val_auc_2: 0.9966\n",
      "Epoch 21/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.7524 - accuracy: 0.7651 - auc_2: 0.9919 - val_loss: 0.4430 - val_accuracy: 0.9000 - val_auc_2: 0.9975\n",
      "Epoch 22/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.6162 - accuracy: 0.8125 - auc_2: 0.9936 - val_loss: 0.3603 - val_accuracy: 0.9250 - val_auc_2: 0.9981\n",
      "Epoch 23/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.5121 - accuracy: 0.8467 - auc_2: 0.9955 - val_loss: 0.3319 - val_accuracy: 0.9279 - val_auc_2: 0.9986\n",
      "Epoch 24/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.4407 - accuracy: 0.8612 - auc_2: 0.9968 - val_loss: 0.2954 - val_accuracy: 0.9265 - val_auc_2: 0.9987\n",
      "Epoch 25/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.3932 - accuracy: 0.8792 - auc_2: 0.9972 - val_loss: 0.2367 - val_accuracy: 0.9390 - val_auc_2: 0.9990\n",
      "Epoch 26/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.3501 - accuracy: 0.8903 - auc_2: 0.9972 - val_loss: 0.2260 - val_accuracy: 0.9397 - val_auc_2: 0.9982\n",
      "Epoch 27/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.2972 - accuracy: 0.9136 - auc_2: 0.9981 - val_loss: 0.2005 - val_accuracy: 0.9463 - val_auc_2: 0.9988\n",
      "Epoch 28/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.2698 - accuracy: 0.9164 - auc_2: 0.9985 - val_loss: 0.1787 - val_accuracy: 0.9507 - val_auc_2: 0.9988\n",
      "Epoch 29/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.2679 - accuracy: 0.9156 - auc_2: 0.9981 - val_loss: 0.1912 - val_accuracy: 0.9449 - val_auc_2: 0.9988\n",
      "Epoch 30/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.2436 - accuracy: 0.9270 - auc_2: 0.9984 - val_loss: 0.1911 - val_accuracy: 0.9441 - val_auc_2: 0.9980\n",
      "Epoch 31/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.2260 - accuracy: 0.9333 - auc_2: 0.9985 - val_loss: 0.1684 - val_accuracy: 0.9544 - val_auc_2: 0.9988\n",
      "Epoch 32/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.1940 - accuracy: 0.9406 - auc_2: 0.9990 - val_loss: 0.1648 - val_accuracy: 0.9507 - val_auc_2: 0.9989\n",
      "Epoch 33/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1897 - accuracy: 0.9432 - auc_2: 0.9991 - val_loss: 0.1777 - val_accuracy: 0.9485 - val_auc_2: 0.9981\n",
      "Epoch 34/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1728 - accuracy: 0.9480 - auc_2: 0.9994 - val_loss: 0.1611 - val_accuracy: 0.9537 - val_auc_2: 0.9982\n",
      "Epoch 35/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1657 - accuracy: 0.9520 - auc_2: 0.9987 - val_loss: 0.1362 - val_accuracy: 0.9654 - val_auc_2: 0.9975\n",
      "Epoch 36/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1526 - accuracy: 0.9540 - auc_2: 0.9992 - val_loss: 0.1308 - val_accuracy: 0.9618 - val_auc_2: 0.9979\n",
      "Epoch 37/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1372 - accuracy: 0.9579 - auc_2: 0.9993 - val_loss: 0.1390 - val_accuracy: 0.9647 - val_auc_2: 0.9990\n",
      "Epoch 38/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1373 - accuracy: 0.9588 - auc_2: 0.9992 - val_loss: 0.1266 - val_accuracy: 0.9684 - val_auc_2: 0.9961\n",
      "Epoch 39/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1328 - accuracy: 0.9601 - auc_2: 0.9992 - val_loss: 0.1283 - val_accuracy: 0.9640 - val_auc_2: 0.9972\n",
      "Epoch 40/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1132 - accuracy: 0.9676 - auc_2: 0.9995 - val_loss: 0.1248 - val_accuracy: 0.9625 - val_auc_2: 0.9976\n",
      "Epoch 41/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1182 - accuracy: 0.9651 - auc_2: 0.9993 - val_loss: 0.1391 - val_accuracy: 0.9632 - val_auc_2: 0.9975\n",
      "Epoch 42/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.1098 - accuracy: 0.9660 - auc_2: 0.9997 - val_loss: 0.1221 - val_accuracy: 0.9632 - val_auc_2: 0.9976\n",
      "Epoch 43/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0994 - accuracy: 0.9717 - auc_2: 0.9996 - val_loss: 0.1075 - val_accuracy: 0.9750 - val_auc_2: 0.9980\n",
      "Epoch 44/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0958 - accuracy: 0.9691 - auc_2: 0.9998 - val_loss: 0.1327 - val_accuracy: 0.9632 - val_auc_2: 0.9979\n",
      "Epoch 45/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0982 - accuracy: 0.9699 - auc_2: 0.9995 - val_loss: 0.1090 - val_accuracy: 0.9691 - val_auc_2: 0.9980\n",
      "Epoch 46/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0768 - accuracy: 0.9761 - auc_2: 0.9998 - val_loss: 0.1162 - val_accuracy: 0.9743 - val_auc_2: 0.9969\n",
      "Epoch 47/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0855 - accuracy: 0.9737 - auc_2: 0.9998 - val_loss: 0.1114 - val_accuracy: 0.9706 - val_auc_2: 0.9969\n",
      "Epoch 48/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0660 - accuracy: 0.9801 - auc_2: 0.9999 - val_loss: 0.1221 - val_accuracy: 0.9676 - val_auc_2: 0.9961\n",
      "Epoch 49/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0715 - accuracy: 0.9792 - auc_2: 0.9998 - val_loss: 0.1163 - val_accuracy: 0.9676 - val_auc_2: 0.9973\n",
      "Epoch 50/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.0709 - accuracy: 0.9798 - auc_2: 0.9999 - val_loss: 0.1104 - val_accuracy: 0.9757 - val_auc_2: 0.9969\n",
      "Epoch 51/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0667 - accuracy: 0.9798 - auc_2: 0.9999 - val_loss: 0.1114 - val_accuracy: 0.9721 - val_auc_2: 0.9965\n",
      "Epoch 52/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.0563 - accuracy: 0.9855 - auc_2: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9750 - val_auc_2: 0.9965\n",
      "Epoch 53/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0632 - accuracy: 0.9818 - auc_2: 0.9999 - val_loss: 0.1238 - val_accuracy: 0.9684 - val_auc_2: 0.9965\n",
      "Epoch 54/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0529 - accuracy: 0.9855 - auc_2: 1.0000 - val_loss: 0.1196 - val_accuracy: 0.9669 - val_auc_2: 0.9972\n",
      "Epoch 55/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0546 - accuracy: 0.9835 - auc_2: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9721 - val_auc_2: 0.9958\n",
      "Epoch 56/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0562 - accuracy: 0.9824 - auc_2: 1.0000 - val_loss: 0.1100 - val_accuracy: 0.9743 - val_auc_2: 0.9962\n",
      "Epoch 57/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.0490 - accuracy: 0.9858 - auc_2: 0.9999 - val_loss: 0.1615 - val_accuracy: 0.9581 - val_auc_2: 0.9953\n",
      "Epoch 58/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0486 - accuracy: 0.9851 - auc_2: 1.0000 - val_loss: 0.1178 - val_accuracy: 0.9713 - val_auc_2: 0.9958\n",
      "Epoch 59/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0453 - accuracy: 0.9879 - auc_2: 1.0000 - val_loss: 0.1180 - val_accuracy: 0.9743 - val_auc_2: 0.9958\n",
      "Epoch 60/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.0395 - accuracy: 0.9895 - auc_2: 1.0000 - val_loss: 0.1222 - val_accuracy: 0.9728 - val_auc_2: 0.9954\n",
      "Epoch 61/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0452 - accuracy: 0.9869 - auc_2: 1.0000 - val_loss: 0.1316 - val_accuracy: 0.9676 - val_auc_2: 0.9958\n",
      "Epoch 62/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0463 - accuracy: 0.9860 - auc_2: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9713 - val_auc_2: 0.9961\n",
      "Epoch 63/100\n",
      "169/170 [============================>.] - ETA: 0s - loss: 0.0399 - accuracy: 0.9887 - auc_2: 1.0000\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.0009999999776482583.\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0398 - accuracy: 0.9888 - auc_2: 1.0000 - val_loss: 0.1254 - val_accuracy: 0.9721 - val_auc_2: 0.9954\n",
      "Epoch 64/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0274 - accuracy: 0.9937 - auc_2: 1.0000 - val_loss: 0.1163 - val_accuracy: 0.9750 - val_auc_2: 0.9954\n",
      "Epoch 65/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0308 - accuracy: 0.9915 - auc_2: 0.9999 - val_loss: 0.1153 - val_accuracy: 0.9750 - val_auc_2: 0.9958\n",
      "Epoch 66/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0242 - accuracy: 0.9952 - auc_2: 1.0000 - val_loss: 0.1154 - val_accuracy: 0.9743 - val_auc_2: 0.9958\n",
      "Epoch 67/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0318 - accuracy: 0.9921 - auc_2: 1.0000 - val_loss: 0.1141 - val_accuracy: 0.9750 - val_auc_2: 0.9958\n",
      "Epoch 68/100\n",
      "170/170 [==============================] - 5s 31ms/step - loss: 0.0264 - accuracy: 0.9947 - auc_2: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9743 - val_auc_2: 0.9958\n",
      "Epoch 69/100\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0288 - accuracy: 0.9926 - auc_2: 0.9999 - val_loss: 0.1127 - val_accuracy: 0.9735 - val_auc_2: 0.9958\n",
      "Epoch 70/100\n",
      "169/170 [============================>.] - ETA: 0s - loss: 0.0255 - accuracy: 0.9935 - auc_2: 1.0000Restoring model weights from the end of the best epoch.\n",
      "170/170 [==============================] - 5s 30ms/step - loss: 0.0254 - accuracy: 0.9936 - auc_2: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9735 - val_auc_2: 0.9958\n",
      "Epoch 00070: early stopping\n",
      "Test score: 0.11044448614120483\n",
      "Test accuracy: 0.9757353067398071\n",
      "Test AUC: 0.9968827962875366\n",
      "Test weighted F1 score: 0.9757153238894716\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0  60   0 ...   0   0   0]\n",
      " [  0   0  77 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0 139]], shape=(37, 37), dtype=int32)\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Retrain the Type classifier on this new data.\n",
    "CLASSES = 37\n",
    "X_train, Y_train, X_test, Y_test = load_data(with_normal, 37)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "model = build_model(CLASSES)\n",
    "model = train_model(model, X_train, Y_train, X_test, Y_test, 'q2')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "model.save_weights(\"q2.model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "The test accuracy of this classifier is 97.6%, auc 0.997, and f1 score 0.976. Even with the new class added, the classifier does well which may indicate that the normal samples are different enough to be able to discern them from thhe other types. Of course, further improvement to the model could be done, perhaps by balancing the classes or optimizing the parameters of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Using the newly trained Type Classifier that now has the new class of “normal” as one of the categories re-run the classifier on all of the NT data and determine how many of the Normal samples are misclassified?  What could be a possible explanation of this misclassification? Note that you will need to do some strict partitioning of training and testing data to not run the model on the same data it was trained on.\n",
    "\n",
    "Here, I extract the normal samples from the **test** set from question 2. This ensures that we are not using the data from the training set. We then predict the class and evaluate how well the model predicted the samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.0878828763961792\n",
      "Test accuracy: 0.9928571581840515\n",
      "Test AUC: 0.9962620139122009\n",
      "Test weighted F1 score: 0.996415770609319\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " ...\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0 139]], shape=(37, 37), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# I extract the normal samples from the test data from above. \n",
    "# Then I evaluate the model on this data to obtain metrics.\n",
    "labels = np.argmax(Y_test, axis=-1)\n",
    "idxs = np.where(labels == 36)\n",
    "normal_X_test = X_test[idxs]\n",
    "normal_Y_test = Y_test[idxs]\n",
    "evaluate_model(model, normal_X_test, normal_Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_X_test.shape[0] # one samples misclassified"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "The model predicts 99.3% of the given normal samples correctly. As can be seen from the confusion matrix, there is just one sample out of 140 that is misclassified. Although the models prediction accuracy is high, we have to keep in mind that the test set is quite small, so it may be better to analyze a larger set of normal samples in order to get a better reading of the performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Build a new type classifier that attempts to assign the tissue type to the sample independently of whether the sample is Normal or Tumor.  You might want to use the metadata files in the directory to provide information about which samples are of which type.   \n",
    "\n",
    "For this problem, I use the metadata to build a dataset of tissue type samples. The metadata has pairs primary tumor gene expression and normal gene expression with the tissue type indicated. Once the data has been built, we use this to train and test the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv('./matched_normal_samples/metadata', sep='\\t', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I build the tissue type data based on the metadata.\n",
    "data = []\n",
    "for i, row in metadata.iterrows():\n",
    "    tissue = row[1]\n",
    "    normal =pd.read_csv(f'./matched_normal_samples/normal/{row[4]}', sep= '\\t', header=None, index_col=0)\n",
    "    normal = normal.T\n",
    "    normal.insert(0,'Type',tissue.lower())\n",
    "    tumor = pd.read_csv(f'./matched_normal_samples/tumor/{row[6]}', sep= '\\t', header=None, index_col=0)\n",
    "    tumor = tumor.T\n",
    "    tumor.insert(0,'Type',tissue.lower())\n",
    "    data.append(normal)\n",
    "    data.append(tumor)\n",
    "    \n",
    "q4_data = pd.concat(data, ignore_index =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ENSG00000242268.2</th>\n",
       "      <th>ENSG00000270112.3</th>\n",
       "      <th>ENSG00000167578.15</th>\n",
       "      <th>ENSG00000273842.1</th>\n",
       "      <th>ENSG00000078237.5</th>\n",
       "      <th>ENSG00000146083.10</th>\n",
       "      <th>ENSG00000225275.4</th>\n",
       "      <th>ENSG00000158486.12</th>\n",
       "      <th>ENSG00000198242.12</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000238244.3</th>\n",
       "      <th>ENSG00000186115.11</th>\n",
       "      <th>ENSG00000216352.1</th>\n",
       "      <th>ENSG00000267117.1</th>\n",
       "      <th>ENSG00000273233.1</th>\n",
       "      <th>ENSG00000105063.17</th>\n",
       "      <th>ENSG00000231119.2</th>\n",
       "      <th>ENSG00000280861.1</th>\n",
       "      <th>ENSG00000123685.7</th>\n",
       "      <th>ENSG00000181518.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prostate</td>\n",
       "      <td>908.971090</td>\n",
       "      <td>441.429189</td>\n",
       "      <td>44095.602873</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53905.323252</td>\n",
       "      <td>216301.394386</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1164.771110</td>\n",
       "      <td>2.535086e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29988.524255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1463.422844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>256608.628020</td>\n",
       "      <td>6778.341629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7493.232006</td>\n",
       "      <td>242.437819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prostate</td>\n",
       "      <td>475.025533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40006.150839</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40722.086265</td>\n",
       "      <td>204565.633212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.357288</td>\n",
       "      <td>3.562813e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>159080.638426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>764.780336</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>229729.650111</td>\n",
       "      <td>8576.193419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6091.462691</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uterus</td>\n",
       "      <td>1194.741346</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50417.659949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18940.780352</td>\n",
       "      <td>144624.917524</td>\n",
       "      <td>3008.036722</td>\n",
       "      <td>538.671817</td>\n",
       "      <td>4.668319e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>134.988281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6732.272664</td>\n",
       "      <td>2986.853365</td>\n",
       "      <td>175567.812480</td>\n",
       "      <td>5626.974167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32048.397144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uterus</td>\n",
       "      <td>2499.746120</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>69987.494384</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71333.310950</td>\n",
       "      <td>287859.456853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16016.087270</td>\n",
       "      <td>4.753488e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>141.217357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5030.668211</td>\n",
       "      <td>4166.243533</td>\n",
       "      <td>266034.237164</td>\n",
       "      <td>26980.399659</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22733.131638</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>head and neck</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>106436.627050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133560.240151</td>\n",
       "      <td>133583.146914</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4459.424809</td>\n",
       "      <td>5.493713e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1548.214268</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3151.596520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>331576.152148</td>\n",
       "      <td>2689.048772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3586.059144</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           Type  ENSG00000242268.2  ENSG00000270112.3  ENSG00000167578.15  \\\n",
       "0       prostate         908.971090         441.429189        44095.602873   \n",
       "1       prostate         475.025533           0.000000        40006.150839   \n",
       "2         uterus        1194.741346           0.000000        50417.659949   \n",
       "3         uterus        2499.746120           0.000000        69987.494384   \n",
       "4  head and neck           0.000000           0.000000       106436.627050   \n",
       "\n",
       "0  ENSG00000273842.1  ENSG00000078237.5  ENSG00000146083.10  \\\n",
       "0                0.0       53905.323252       216301.394386   \n",
       "1                0.0       40722.086265       204565.633212   \n",
       "2                0.0       18940.780352       144624.917524   \n",
       "3                0.0       71333.310950       287859.456853   \n",
       "4                0.0      133560.240151       133583.146914   \n",
       "\n",
       "0  ENSG00000225275.4  ENSG00000158486.12  ENSG00000198242.12  ...  \\\n",
       "0           0.000000         1164.771110        2.535086e+06  ...   \n",
       "1           0.000000          180.357288        3.562813e+06  ...   \n",
       "2        3008.036722          538.671817        4.668319e+06  ...   \n",
       "3           0.000000        16016.087270        4.753488e+06  ...   \n",
       "4           0.000000         4459.424809        5.493713e+06  ...   \n",
       "\n",
       "0  ENSG00000238244.3  ENSG00000186115.11  ENSG00000216352.1  \\\n",
       "0                0.0        29988.524255                0.0   \n",
       "1                0.0       159080.638426                0.0   \n",
       "2                0.0          134.988281                0.0   \n",
       "3                0.0          141.217357                0.0   \n",
       "4                0.0         1548.214268                0.0   \n",
       "\n",
       "0  ENSG00000267117.1  ENSG00000273233.1  ENSG00000105063.17  \\\n",
       "0        1463.422844           0.000000       256608.628020   \n",
       "1         764.780336           0.000000       229729.650111   \n",
       "2        6732.272664        2986.853365       175567.812480   \n",
       "3        5030.668211        4166.243533       266034.237164   \n",
       "4        3151.596520           0.000000       331576.152148   \n",
       "\n",
       "0  ENSG00000231119.2  ENSG00000280861.1  ENSG00000123685.7  ENSG00000181518.3  \n",
       "0        6778.341629                0.0        7493.232006         242.437819  \n",
       "1        8576.193419                0.0        6091.462691           0.000000  \n",
       "2        5626.974167                0.0       32048.397144           0.000000  \n",
       "3       26980.399659                0.0       22733.131638           0.000000  \n",
       "4        2689.048772                0.0        3586.059144           0.000000  \n",
       "\n",
       "[5 rows x 60484 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the data.\n",
    "q4_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ENSG00000242268.2</th>\n",
       "      <th>ENSG00000270112.3</th>\n",
       "      <th>ENSG00000167578.15</th>\n",
       "      <th>ENSG00000273842.1</th>\n",
       "      <th>ENSG00000078237.5</th>\n",
       "      <th>ENSG00000146083.10</th>\n",
       "      <th>ENSG00000225275.4</th>\n",
       "      <th>ENSG00000158486.12</th>\n",
       "      <th>ENSG00000198242.12</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000238244.3</th>\n",
       "      <th>ENSG00000186115.11</th>\n",
       "      <th>ENSG00000216352.1</th>\n",
       "      <th>ENSG00000267117.1</th>\n",
       "      <th>ENSG00000273233.1</th>\n",
       "      <th>ENSG00000105063.17</th>\n",
       "      <th>ENSG00000231119.2</th>\n",
       "      <th>ENSG00000280861.1</th>\n",
       "      <th>ENSG00000123685.7</th>\n",
       "      <th>ENSG00000181518.3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>prostate</td>\n",
       "      <td>6.812313</td>\n",
       "      <td>6.090018</td>\n",
       "      <td>10.694115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.894985</td>\n",
       "      <td>12.284428</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.060280</td>\n",
       "      <td>14.745738</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.308570</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.288533</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.455307</td>\n",
       "      <td>8.821488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.921755</td>\n",
       "      <td>5.490745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>prostate</td>\n",
       "      <td>6.163369</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.596788</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.614526</td>\n",
       "      <td>12.228644</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.194940</td>\n",
       "      <td>15.086061</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.977167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.639589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.344658</td>\n",
       "      <td>9.056745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.714644</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uterus</td>\n",
       "      <td>7.085685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.828097</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.849073</td>\n",
       "      <td>11.881899</td>\n",
       "      <td>8.009043</td>\n",
       "      <td>6.289107</td>\n",
       "      <td>15.356310</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.905188</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.814668</td>\n",
       "      <td>8.001976</td>\n",
       "      <td>12.075781</td>\n",
       "      <td>8.635327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.375002</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>uterus</td>\n",
       "      <td>7.823944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.156072</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.175119</td>\n",
       "      <td>12.570228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.681349</td>\n",
       "      <td>15.374389</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.950300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.523308</td>\n",
       "      <td>8.334770</td>\n",
       "      <td>12.491380</td>\n",
       "      <td>10.202866</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.031579</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>head and neck</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.575305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.802308</td>\n",
       "      <td>11.802479</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.402775</td>\n",
       "      <td>15.519115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.344857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.055664</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.711613</td>\n",
       "      <td>7.896943</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.184809</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 60484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "0           Type  ENSG00000242268.2  ENSG00000270112.3  ENSG00000167578.15  \\\n",
       "0       prostate           6.812313           6.090018           10.694115   \n",
       "1       prostate           6.163369           0.000000           10.596788   \n",
       "2         uterus           7.085685           0.000000           10.828097   \n",
       "3         uterus           7.823944           0.000000           11.156072   \n",
       "4  head and neck           0.000000           0.000000           11.575305   \n",
       "\n",
       "0  ENSG00000273842.1  ENSG00000078237.5  ENSG00000146083.10  \\\n",
       "0                0.0          10.894985           12.284428   \n",
       "1                0.0          10.614526           12.228644   \n",
       "2                0.0           9.849073           11.881899   \n",
       "3                0.0          11.175119           12.570228   \n",
       "4                0.0          11.802308           11.802479   \n",
       "\n",
       "0  ENSG00000225275.4  ENSG00000158486.12  ENSG00000198242.12  ...  \\\n",
       "0           0.000000            7.060280           14.745738  ...   \n",
       "1           0.000000            5.194940           15.086061  ...   \n",
       "2           8.009043            6.289107           15.356310  ...   \n",
       "3           0.000000            9.681349           15.374389  ...   \n",
       "4           0.000000            8.402775           15.519115  ...   \n",
       "\n",
       "0  ENSG00000238244.3  ENSG00000186115.11  ENSG00000216352.1  \\\n",
       "0                0.0           10.308570                0.0   \n",
       "1                0.0           11.977167                0.0   \n",
       "2                0.0            4.905188                0.0   \n",
       "3                0.0            4.950300                0.0   \n",
       "4                0.0            7.344857                0.0   \n",
       "\n",
       "0  ENSG00000267117.1  ENSG00000273233.1  ENSG00000105063.17  \\\n",
       "0           7.288533           0.000000           12.455307   \n",
       "1           6.639589           0.000000           12.344658   \n",
       "2           8.814668           8.001976           12.075781   \n",
       "3           8.523308           8.334770           12.491380   \n",
       "4           8.055664           0.000000           12.711613   \n",
       "\n",
       "0  ENSG00000231119.2  ENSG00000280861.1  ENSG00000123685.7  ENSG00000181518.3  \n",
       "0           8.821488                0.0           8.921755           5.490745  \n",
       "1           9.056745                0.0           8.714644           0.000000  \n",
       "2           8.635327                0.0          10.375002           0.000000  \n",
       "3          10.202866                0.0          10.031579           0.000000  \n",
       "4           7.896943                0.0           8.184809           0.000000  \n",
       "\n",
       "[5 rows x 60484 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I log-transform the data and zero the -inf to match the form that was used for training.          \n",
    "q4_data.iloc[:,1:] = q4_data.iloc[:,1:].transform(np.log).replace(to_replace = np.NINF, value = 0)\n",
    "q4_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I map the class name to integers\n",
    "mapping = {t:i for i, t in enumerate(q4_data.Type.unique())}\n",
    "q4_data.Type = q4_data.Type.map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " # Number of tissue types (classes)\n",
    "q4_data.Type.hist(bins=len(q4_data.Type.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classes are very imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (1161, 60483, 1)\n",
      "X_test shape: (291, 60483, 1)\n",
      "Y_train shape: (1161, 18)\n",
      "Y_test shape: (291, 18)\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_6 (Conv1D)            (None, 60464, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 60464, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 12092, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 12083, 64)         41024     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 12083, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 1208, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 77312)             0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 200)               15462600  \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 18)                378       \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 18)                0         \n",
      "=================================================================\n",
      "Total params: 15,509,366\n",
      "Trainable params: 15,509,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "37/37 [==============================] - 3s 86ms/step - loss: 2.6419 - accuracy: 0.1611 - auc_3: 0.7053 - val_loss: 2.6320 - val_accuracy: 0.1409 - val_auc_3: 0.7074\n",
      "Epoch 2/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 2.5472 - accuracy: 0.1662 - auc_3: 0.7373 - val_loss: 2.5672 - val_accuracy: 0.1409 - val_auc_3: 0.7283\n",
      "Epoch 3/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 2.5182 - accuracy: 0.1697 - auc_3: 0.7483 - val_loss: 2.5295 - val_accuracy: 0.1718 - val_auc_3: 0.7501\n",
      "Epoch 4/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 2.4677 - accuracy: 0.1619 - auc_3: 0.7677 - val_loss: 2.5254 - val_accuracy: 0.1409 - val_auc_3: 0.7679\n",
      "Epoch 5/100\n",
      "37/37 [==============================] - 3s 74ms/step - loss: 2.4549 - accuracy: 0.1748 - auc_3: 0.7721 - val_loss: 2.4730 - val_accuracy: 0.1718 - val_auc_3: 0.7769\n",
      "Epoch 6/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 2.4202 - accuracy: 0.1748 - auc_3: 0.7814 - val_loss: 2.4544 - val_accuracy: 0.1718 - val_auc_3: 0.7852\n",
      "Epoch 7/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 2.3966 - accuracy: 0.1843 - auc_3: 0.7889 - val_loss: 2.4995 - val_accuracy: 0.1409 - val_auc_3: 0.7786\n",
      "Epoch 8/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 2.3658 - accuracy: 0.1904 - auc_3: 0.7967 - val_loss: 2.4157 - val_accuracy: 0.1718 - val_auc_3: 0.7867\n",
      "Epoch 9/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 2.3598 - accuracy: 0.2016 - auc_3: 0.7981 - val_loss: 2.4993 - val_accuracy: 0.1409 - val_auc_3: 0.7931\n",
      "Epoch 10/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 2.3372 - accuracy: 0.2016 - auc_3: 0.8033 - val_loss: 2.3920 - val_accuracy: 0.1409 - val_auc_3: 0.8035\n",
      "Epoch 11/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 2.3213 - accuracy: 0.2317 - auc_3: 0.8067 - val_loss: 2.3655 - val_accuracy: 0.1649 - val_auc_3: 0.8126\n",
      "Epoch 12/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 2.2942 - accuracy: 0.2705 - auc_3: 0.8131 - val_loss: 2.3211 - val_accuracy: 0.2027 - val_auc_3: 0.8191\n",
      "Epoch 13/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 2.2645 - accuracy: 0.2498 - auc_3: 0.8207 - val_loss: 2.2893 - val_accuracy: 0.2715 - val_auc_3: 0.8309\n",
      "Epoch 14/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 2.2372 - accuracy: 0.2894 - auc_3: 0.8262 - val_loss: 2.2791 - val_accuracy: 0.2199 - val_auc_3: 0.8247\n",
      "Epoch 15/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 2.1803 - accuracy: 0.3066 - auc_3: 0.8378 - val_loss: 2.2154 - val_accuracy: 0.4674 - val_auc_3: 0.8503\n",
      "Epoch 16/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 2.1335 - accuracy: 0.3273 - auc_3: 0.8466 - val_loss: 2.1669 - val_accuracy: 0.3574 - val_auc_3: 0.8446\n",
      "Epoch 17/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 2.0843 - accuracy: 0.3540 - auc_3: 0.8551 - val_loss: 2.1310 - val_accuracy: 0.3574 - val_auc_3: 0.8481\n",
      "Epoch 18/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 2.0076 - accuracy: 0.3816 - auc_3: 0.8675 - val_loss: 2.1217 - val_accuracy: 0.3162 - val_auc_3: 0.8451\n",
      "Epoch 19/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.9293 - accuracy: 0.4100 - auc_3: 0.8792 - val_loss: 1.9180 - val_accuracy: 0.4502 - val_auc_3: 0.8774\n",
      "Epoch 20/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 1.7941 - accuracy: 0.4686 - auc_3: 0.8994 - val_loss: 1.8564 - val_accuracy: 0.5533 - val_auc_3: 0.8978\n",
      "Epoch 21/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.6634 - accuracy: 0.5323 - auc_3: 0.9138 - val_loss: 1.8013 - val_accuracy: 0.5017 - val_auc_3: 0.8924\n",
      "Epoch 22/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.5263 - accuracy: 0.6038 - auc_3: 0.9279 - val_loss: 1.5401 - val_accuracy: 0.6942 - val_auc_3: 0.9252\n",
      "Epoch 23/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 1.3799 - accuracy: 0.6624 - auc_3: 0.9417 - val_loss: 1.7612 - val_accuracy: 0.3986 - val_auc_3: 0.8943\n",
      "Epoch 24/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 1.2479 - accuracy: 0.7089 - auc_3: 0.9493 - val_loss: 1.2879 - val_accuracy: 0.7079 - val_auc_3: 0.9412\n",
      "Epoch 25/100\n",
      "37/37 [==============================] - 3s 81ms/step - loss: 1.0851 - accuracy: 0.7571 - auc_3: 0.9611 - val_loss: 1.0766 - val_accuracy: 0.8144 - val_auc_3: 0.9525\n",
      "Epoch 26/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.9577 - accuracy: 0.7838 - auc_3: 0.9688 - val_loss: 1.0573 - val_accuracy: 0.7904 - val_auc_3: 0.9516\n",
      "Epoch 27/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.8773 - accuracy: 0.7907 - auc_3: 0.9731 - val_loss: 0.9042 - val_accuracy: 0.8213 - val_auc_3: 0.9661\n",
      "Epoch 28/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 0.7953 - accuracy: 0.8122 - auc_3: 0.9778 - val_loss: 1.1038 - val_accuracy: 0.7904 - val_auc_3: 0.9619\n",
      "Epoch 29/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.6926 - accuracy: 0.8338 - auc_3: 0.9830 - val_loss: 0.7488 - val_accuracy: 0.8419 - val_auc_3: 0.9786\n",
      "Epoch 30/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.6556 - accuracy: 0.8381 - auc_3: 0.9843 - val_loss: 1.1362 - val_accuracy: 0.6254 - val_auc_3: 0.9579\n",
      "Epoch 31/100\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.6024 - accuracy: 0.8467 - auc_3: 0.9872 - val_loss: 0.6918 - val_accuracy: 0.8488 - val_auc_3: 0.9823\n",
      "Epoch 32/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 0.5288 - accuracy: 0.8725 - auc_3: 0.9899 - val_loss: 0.5829 - val_accuracy: 0.8454 - val_auc_3: 0.9844\n",
      "Epoch 33/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.4889 - accuracy: 0.8829 - auc_3: 0.9911 - val_loss: 0.6164 - val_accuracy: 0.8454 - val_auc_3: 0.9781\n",
      "Epoch 34/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.4491 - accuracy: 0.8863 - auc_3: 0.9931 - val_loss: 0.5730 - val_accuracy: 0.8591 - val_auc_3: 0.9816\n",
      "Epoch 35/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 0.4118 - accuracy: 0.8984 - auc_3: 0.9945 - val_loss: 0.9124 - val_accuracy: 0.7423 - val_auc_3: 0.9623\n",
      "Epoch 36/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.3939 - accuracy: 0.9027 - auc_3: 0.9944 - val_loss: 0.4859 - val_accuracy: 0.8763 - val_auc_3: 0.9901\n",
      "Epoch 37/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.3638 - accuracy: 0.9061 - auc_3: 0.9966 - val_loss: 0.5256 - val_accuracy: 0.8832 - val_auc_3: 0.9849\n",
      "Epoch 38/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.3350 - accuracy: 0.9104 - auc_3: 0.9970 - val_loss: 0.5079 - val_accuracy: 0.8694 - val_auc_3: 0.9883\n",
      "Epoch 39/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.3270 - accuracy: 0.9147 - auc_3: 0.9970 - val_loss: 0.4604 - val_accuracy: 0.8935 - val_auc_3: 0.9906\n",
      "Epoch 40/100\n",
      "37/37 [==============================] - 3s 76ms/step - loss: 0.2979 - accuracy: 0.9345 - auc_3: 0.9978 - val_loss: 0.4481 - val_accuracy: 0.8832 - val_auc_3: 0.9888\n",
      "Epoch 41/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.2680 - accuracy: 0.9371 - auc_3: 0.9983 - val_loss: 0.4326 - val_accuracy: 0.8832 - val_auc_3: 0.9907\n",
      "Epoch 42/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.2756 - accuracy: 0.9285 - auc_3: 0.9981 - val_loss: 0.4903 - val_accuracy: 0.8729 - val_auc_3: 0.9879\n",
      "Epoch 43/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.2492 - accuracy: 0.9397 - auc_3: 0.9986 - val_loss: 0.4109 - val_accuracy: 0.9072 - val_auc_3: 0.9933\n",
      "Epoch 44/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.2308 - accuracy: 0.9388 - auc_3: 0.9989 - val_loss: 0.6266 - val_accuracy: 0.8385 - val_auc_3: 0.9759\n",
      "Epoch 45/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.2268 - accuracy: 0.9371 - auc_3: 0.9989 - val_loss: 0.4122 - val_accuracy: 0.9175 - val_auc_3: 0.9906\n",
      "Epoch 46/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.2045 - accuracy: 0.9423 - auc_3: 0.9991 - val_loss: 0.4962 - val_accuracy: 0.8832 - val_auc_3: 0.9913\n",
      "Epoch 47/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.2086 - accuracy: 0.9440 - auc_3: 0.9989 - val_loss: 0.4214 - val_accuracy: 0.9244 - val_auc_3: 0.9886\n",
      "Epoch 48/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1873 - accuracy: 0.9526 - auc_3: 0.9993 - val_loss: 0.4175 - val_accuracy: 0.9072 - val_auc_3: 0.9891\n",
      "Epoch 49/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1725 - accuracy: 0.9518 - auc_3: 0.9994 - val_loss: 0.4051 - val_accuracy: 0.9038 - val_auc_3: 0.9920\n",
      "Epoch 50/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.1525 - accuracy: 0.9638 - auc_3: 0.9996 - val_loss: 0.3475 - val_accuracy: 0.9278 - val_auc_3: 0.9921\n",
      "Epoch 51/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1558 - accuracy: 0.9552 - auc_3: 0.9995 - val_loss: 0.3705 - val_accuracy: 0.9038 - val_auc_3: 0.9947\n",
      "Epoch 52/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1643 - accuracy: 0.9561 - auc_3: 0.9994 - val_loss: 0.3433 - val_accuracy: 0.9141 - val_auc_3: 0.9925\n",
      "Epoch 53/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1258 - accuracy: 0.9759 - auc_3: 0.9997 - val_loss: 0.3401 - val_accuracy: 0.9278 - val_auc_3: 0.9926\n",
      "Epoch 54/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.1337 - accuracy: 0.9655 - auc_3: 0.9997 - val_loss: 0.4767 - val_accuracy: 0.8797 - val_auc_3: 0.9895\n",
      "Epoch 55/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1340 - accuracy: 0.9690 - auc_3: 0.9997 - val_loss: 0.3911 - val_accuracy: 0.8969 - val_auc_3: 0.9942\n",
      "Epoch 56/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1361 - accuracy: 0.9638 - auc_3: 0.9997 - val_loss: 0.3564 - val_accuracy: 0.9278 - val_auc_3: 0.9907\n",
      "Epoch 57/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1149 - accuracy: 0.9716 - auc_3: 0.9998 - val_loss: 0.3288 - val_accuracy: 0.9244 - val_auc_3: 0.9926\n",
      "Epoch 58/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1049 - accuracy: 0.9742 - auc_3: 0.9998 - val_loss: 0.3227 - val_accuracy: 0.9244 - val_auc_3: 0.9928\n",
      "Epoch 59/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.1054 - accuracy: 0.9733 - auc_3: 0.9998 - val_loss: 0.3486 - val_accuracy: 0.9244 - val_auc_3: 0.9926\n",
      "Epoch 60/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.1021 - accuracy: 0.9742 - auc_3: 0.9998 - val_loss: 0.3427 - val_accuracy: 0.9347 - val_auc_3: 0.9925\n",
      "Epoch 61/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0818 - accuracy: 0.9828 - auc_3: 0.9999 - val_loss: 0.3377 - val_accuracy: 0.9141 - val_auc_3: 0.9927\n",
      "Epoch 62/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.1038 - accuracy: 0.9759 - auc_3: 0.9998 - val_loss: 0.4086 - val_accuracy: 0.9072 - val_auc_3: 0.9916\n",
      "Epoch 63/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 0.0839 - accuracy: 0.9871 - auc_3: 0.9999 - val_loss: 0.4284 - val_accuracy: 0.9003 - val_auc_3: 0.9911\n",
      "Epoch 64/100\n",
      "37/37 [==============================] - 3s 75ms/step - loss: 0.0992 - accuracy: 0.9793 - auc_3: 0.9998 - val_loss: 0.3604 - val_accuracy: 0.9175 - val_auc_3: 0.9926\n",
      "Epoch 65/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0877 - accuracy: 0.9845 - auc_3: 0.9998 - val_loss: 0.3255 - val_accuracy: 0.9313 - val_auc_3: 0.9943\n",
      "Epoch 66/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0746 - accuracy: 0.9854 - auc_3: 0.9999 - val_loss: 0.4065 - val_accuracy: 0.9210 - val_auc_3: 0.9869\n",
      "Epoch 67/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0792 - accuracy: 0.9819 - auc_3: 0.9999 - val_loss: 0.3172 - val_accuracy: 0.9313 - val_auc_3: 0.9930\n",
      "Epoch 68/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0649 - accuracy: 0.9888 - auc_3: 0.9999 - val_loss: 0.4102 - val_accuracy: 0.9175 - val_auc_3: 0.9888\n",
      "Epoch 69/100\n",
      "37/37 [==============================] - 3s 80ms/step - loss: 0.0769 - accuracy: 0.9811 - auc_3: 0.9999 - val_loss: 0.3066 - val_accuracy: 0.9416 - val_auc_3: 0.9931\n",
      "Epoch 70/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0662 - accuracy: 0.9862 - auc_3: 0.9999 - val_loss: 0.3166 - val_accuracy: 0.9347 - val_auc_3: 0.9933\n",
      "Epoch 71/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0722 - accuracy: 0.9836 - auc_3: 0.9999 - val_loss: 0.3124 - val_accuracy: 0.9381 - val_auc_3: 0.9933\n",
      "Epoch 72/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0678 - accuracy: 0.9854 - auc_3: 0.9999 - val_loss: 0.3389 - val_accuracy: 0.9347 - val_auc_3: 0.9928\n",
      "Epoch 73/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0609 - accuracy: 0.9897 - auc_3: 0.9999 - val_loss: 0.3634 - val_accuracy: 0.9210 - val_auc_3: 0.9926\n",
      "Epoch 74/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0540 - accuracy: 0.9922 - auc_3: 1.0000 - val_loss: 0.3302 - val_accuracy: 0.9244 - val_auc_3: 0.9930\n",
      "Epoch 75/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0495 - accuracy: 0.9914 - auc_3: 1.0000 - val_loss: 0.3117 - val_accuracy: 0.9416 - val_auc_3: 0.9932\n",
      "Epoch 76/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0669 - accuracy: 0.9845 - auc_3: 0.9999 - val_loss: 0.4737 - val_accuracy: 0.8969 - val_auc_3: 0.9892\n",
      "Epoch 77/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0577 - accuracy: 0.9897 - auc_3: 0.9999 - val_loss: 0.8091 - val_accuracy: 0.8179 - val_auc_3: 0.9713\n",
      "Epoch 78/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0534 - accuracy: 0.9897 - auc_3: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9313 - val_auc_3: 0.9929\n",
      "Epoch 79/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0517 - accuracy: 0.9905 - auc_3: 1.0000 - val_loss: 0.2926 - val_accuracy: 0.9347 - val_auc_3: 0.9935\n",
      "Epoch 80/100\n",
      "37/37 [==============================] - 3s 77ms/step - loss: 0.0387 - accuracy: 0.9914 - auc_3: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9381 - val_auc_3: 0.9934\n",
      "Epoch 81/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0487 - accuracy: 0.9914 - auc_3: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9175 - val_auc_3: 0.9928\n",
      "Epoch 82/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0426 - accuracy: 0.9931 - auc_3: 1.0000 - val_loss: 0.3148 - val_accuracy: 0.9347 - val_auc_3: 0.9935\n",
      "Epoch 83/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0477 - accuracy: 0.9871 - auc_3: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.8866 - val_auc_3: 0.9836\n",
      "Epoch 84/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0448 - accuracy: 0.9914 - auc_3: 1.0000 - val_loss: 0.3096 - val_accuracy: 0.9313 - val_auc_3: 0.9935\n",
      "Epoch 85/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0467 - accuracy: 0.9914 - auc_3: 0.9999 - val_loss: 0.2965 - val_accuracy: 0.9210 - val_auc_3: 0.9951\n",
      "Epoch 86/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0569 - accuracy: 0.9854 - auc_3: 0.9999 - val_loss: 0.2888 - val_accuracy: 0.9313 - val_auc_3: 0.9936\n",
      "Epoch 87/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0395 - accuracy: 0.9897 - auc_3: 1.0000 - val_loss: 0.2994 - val_accuracy: 0.9313 - val_auc_3: 0.9937\n",
      "Epoch 88/100\n",
      "37/37 [==============================] - 3s 78ms/step - loss: 0.0325 - accuracy: 0.9940 - auc_3: 1.0000 - val_loss: 0.3052 - val_accuracy: 0.9416 - val_auc_3: 0.9935\n",
      "Epoch 89/100\n",
      "36/37 [============================>.] - ETA: 0s - loss: 0.0395 - accuracy: 0.9905 - auc_3: 1.0000Restoring model weights from the end of the best epoch.\n",
      "37/37 [==============================] - 3s 79ms/step - loss: 0.0392 - accuracy: 0.9905 - auc_3: 1.0000 - val_loss: 0.3063 - val_accuracy: 0.9347 - val_auc_3: 0.9919\n",
      "Epoch 00089: early stopping\n",
      "Test score: 0.3065599799156189\n",
      "Test accuracy: 0.9415807723999023\n",
      "Test AUC: 0.9931267499923706\n",
      "Test weighted F1 score: 0.9243386155878575\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[23  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 12  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 20  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 46  0  0  0  1  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 50  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  6  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 17  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0 40  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 25  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  0  0  0  0  0  0 12  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  1  1  0  1  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  2  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0]], shape=(17, 17), dtype=int32)\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# I build a tissue type classifier with gene expression as the features.\n",
    "EPOCH = 100\n",
    "BATCH = 32\n",
    "CLASSES = 18\n",
    "\n",
    "PL = 60484   # 1 + 60483 these are the width of the RNAseq datasets\n",
    "P     = 60483   # 60483\n",
    "DR    = 0.1 \n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_data(q4_data, CLASSES)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "model = build_model(CLASSES)\n",
    "model = train_model(model, X_train, Y_train, X_test, Y_test, 'q4')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "model.save_weights(\"q4.model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "Using the metadata, I put together the data with the expression data as the features and the tissue type as the classes. In total there were 17 classes or tissue types. Then I built the model architecture and trained the model with this data. In total there were about 1400 samples and 20% of those samples were used for testing and the rest for training. The test accuracy was about 94.2%. This is not as good as the previous classifiers. It is likely due to the class imbalance but it could also be that this data needs a slightly different model with different parameters. With more time, we could adjust the model parameters. In addition, not all classes are represented in the test data (due to the imbalance of datasets). We could test the model with a larger test set that has all the classes but with the same distribution as the train set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 5: Using ideas discussed in class, use an unsupervised learning method to cluster the Cancer Type sample data and assign your own “types” to the clusters and use those labels to train a type classifier.  Describe your approach and report on the results.\n",
    "\n",
    "For this problem, I decided to use a dimension reduction technique called UMAP to visualize the data and observe the natural clusters that form. Based on this I can choose various k-values to perform k-means clustering. There were about 10+ clusters in UMAP, so I performed k-means clustering with `k = 10, 12, 14, 16, 18, 20` and made an elbow plot of the within cluster sum of squared errors (SSE). The SSE is a measure of how internally coherent the clusters are. We choose the 'optimal' `k` value which is the `k` that lies at the elbow. Then I perform k-means for that `k` and use the cluster labels as the class types and retrain the classifier with these new 'types'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create elbow plot for various k values\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def cluster(method, n_clusters, X, plot=False):\n",
    "    \"\"\"Cluster the data with various clustering methods.\"\"\"\n",
    "    \n",
    "    if method=='kmeans':\n",
    "        from sklearn.cluster import KMeans\n",
    "        model = KMeans(n_clusters=n_clusters, random_state=0).fit(X)\n",
    "        y=model.labels_\n",
    "        \n",
    "    elif method=='agglomerative':\n",
    "        from sklearn.cluster import AgglomerativeClustering\n",
    "        model = AgglomerativeClustering(n_clusters=n_clusters).fit(X)\n",
    "        y=model.labels_\n",
    "\n",
    "    else:\n",
    "        print('Invalid clustering method')\n",
    "        sys.exit()\n",
    "    if plot:\n",
    "        plot_clusters(X,y,2)\n",
    "    if n_clusters>1:\n",
    "        from sklearn import metrics\n",
    "        print(\"Silhouette Coefficient: %0.3f\"\n",
    "          % metrics.silhouette_score(X, y))\n",
    "        print(\"Davies Bouldin Score: %0.3f\" % metrics.davies_bouldin_score(X,y))\n",
    "        print(\"Calinski Harabasz Score: %0.3f\" % metrics.calinski_harabasz_score(X,y))\n",
    "    return model\n",
    "\n",
    "def plot_clusters(X,y,n_components):\n",
    "    \"\"\"Performs PCA and visualizes the data in either a 2D or 3D plot.\"\"\"\n",
    "    \n",
    "    np.random.seed(0)\n",
    "    if n_components==2:\n",
    "        pca=PCA(n_components=2).fit(X)\n",
    "        pca_2d = pca.transform(X)\n",
    "        plt.figure(figsize=(16, 10))\n",
    "        s = plt.scatter(pca_2d[:, 0], pca_2d[:, 1], c=y, cmap='viridis')\n",
    "        \n",
    "    elif n_components==3:\n",
    "        pca = PCA(n_components=3).fit(X)\n",
    "        pca_3d = pca.transform(X)\n",
    "        ax = plt.figure(figsize=(16, 10)).gca(projection='3d')\n",
    "        s = ax.scatter(\n",
    "            xs=pca_3d[:,0],\n",
    "            ys=pca_3d[:,1],\n",
    "            zs=pca_3d[:,2],\n",
    "            c=y,\n",
    "            cmap='viridis'\n",
    "        )\n",
    "        ax.set_xlabel('pca-one')\n",
    "        ax.set_ylabel('pca-two')\n",
    "        ax.set_zlabel('pca-three')\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid number of components.\")\n",
    "        \n",
    "    plt.legend(*s.legend_elements(), loc=1)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fa785cf29a0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# I use UMAP a dimension reduction technique to visualize the data in 2D. \n",
    "# Then I see generally how many natural clusters there are.\n",
    "import umap\n",
    "\n",
    "standard_embedding = umap.UMAP(random_state=42).fit_transform(tc_coding.iloc[:,1:])\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(standard_embedding[:, 0], standard_embedding[:, 1], s=10, cmap='Spectral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "Silhouette Coefficient: 0.723\n",
      "Davies Bouldin Score: 0.366\n",
      "Calinski Harabasz Score: 18592.627\n",
      "12\n",
      "Silhouette Coefficient: 0.796\n",
      "Davies Bouldin Score: 0.260\n",
      "Calinski Harabasz Score: 42666.158\n",
      "14\n",
      "Silhouette Coefficient: 0.758\n",
      "Davies Bouldin Score: 0.315\n",
      "Calinski Harabasz Score: 54439.819\n",
      "16\n",
      "Silhouette Coefficient: 0.742\n",
      "Davies Bouldin Score: 0.355\n",
      "Calinski Harabasz Score: 67621.010\n",
      "18\n",
      "Silhouette Coefficient: 0.756\n",
      "Davies Bouldin Score: 0.337\n",
      "Calinski Harabasz Score: 92490.802\n",
      "20\n",
      "Silhouette Coefficient: 0.781\n",
      "Davies Bouldin Score: 0.292\n",
      "Calinski Harabasz Score: 115155.994\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Based on the UMAP, I test several probable values for k and I use the elbow plot to determine the best k for clustering.\n",
    "sse={}\n",
    "for k in [10,12,14,16,18,20]:\n",
    "    print(k)\n",
    "    model = cluster('kmeans', k, standard_embedding)\n",
    "    sse[k] = model.inertia_\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(list(sse.keys()), list(sse.values()))\n",
    "plt.xlabel(\"Number of cluster\")\n",
    "plt.ylabel(\"SSE\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Coefficient: 0.796\n",
      "Davies Bouldin Score: 0.260\n",
      "Calinski Harabasz Score: 42666.158\n"
     ]
    }
   ],
   "source": [
    "model = cluster('kmeans', 12, standard_embedding, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>ENSG00000000003.13</th>\n",
       "      <th>ENSG00000000005.5</th>\n",
       "      <th>ENSG00000000419.11</th>\n",
       "      <th>ENSG00000000457.12</th>\n",
       "      <th>ENSG00000000460.15</th>\n",
       "      <th>ENSG00000000938.11</th>\n",
       "      <th>ENSG00000000971.14</th>\n",
       "      <th>ENSG00000001036.12</th>\n",
       "      <th>ENSG00000001084.9</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000269699.4</th>\n",
       "      <th>ENSG00000269711.1</th>\n",
       "      <th>ENSG00000269741.4</th>\n",
       "      <th>ENSG00000269749.1</th>\n",
       "      <th>ENSG00000269755.1</th>\n",
       "      <th>ENSG00000269846.1</th>\n",
       "      <th>ENSG00000269855.2</th>\n",
       "      <th>ENSG00000269858.4</th>\n",
       "      <th>ENSG00000269881.1</th>\n",
       "      <th>ENSG00000269883.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.7</td>\n",
       "      <td>19.1</td>\n",
       "      <td>17.1</td>\n",
       "      <td>15.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18.3</td>\n",
       "      <td>18.9</td>\n",
       "      <td>16.3</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.9</td>\n",
       "      <td>9.4</td>\n",
       "      <td>11.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>11.2</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>16.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>14.9</td>\n",
       "      <td>17.4</td>\n",
       "      <td>17.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>17.7</td>\n",
       "      <td>...</td>\n",
       "      <td>10.2</td>\n",
       "      <td>10.8</td>\n",
       "      <td>8.4</td>\n",
       "      <td>10.5</td>\n",
       "      <td>10.2</td>\n",
       "      <td>7.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>9.8</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>9.7</td>\n",
       "      <td>20.4</td>\n",
       "      <td>16.4</td>\n",
       "      <td>14.2</td>\n",
       "      <td>13.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>20.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>...</td>\n",
       "      <td>9.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>10.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>9.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>16.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>16.2</td>\n",
       "      <td>19.2</td>\n",
       "      <td>18.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.1</td>\n",
       "      <td>8.9</td>\n",
       "      <td>13.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>10.2</td>\n",
       "      <td>19.3</td>\n",
       "      <td>15.5</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>17.3</td>\n",
       "      <td>18.7</td>\n",
       "      <td>17.4</td>\n",
       "      <td>...</td>\n",
       "      <td>8.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.6</td>\n",
       "      <td>10.6</td>\n",
       "      <td>11.5</td>\n",
       "      <td>18.6</td>\n",
       "      <td>10.1</td>\n",
       "      <td>12.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19562 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Type  ENSG00000000003.13  ENSG00000000005.5  ENSG00000000419.11  \\\n",
       "0     1                19.0               11.7                19.1   \n",
       "1     6                16.5                0.0                21.3   \n",
       "2     0                19.8                9.7                20.4   \n",
       "3     2                16.7                0.0                19.3   \n",
       "4     1                16.4               10.2                19.3   \n",
       "\n",
       "   ENSG00000000457.12  ENSG00000000460.15  ENSG00000000938.11  \\\n",
       "0                17.1                15.5                16.0   \n",
       "1                15.5                14.9                17.4   \n",
       "2                16.4                14.2                13.9   \n",
       "3                15.9                16.1                16.8   \n",
       "4                15.5                15.0                15.6   \n",
       "\n",
       "   ENSG00000000971.14  ENSG00000001036.12  ENSG00000001084.9  ...  \\\n",
       "0                18.3                18.9               16.3  ...   \n",
       "1                17.6                20.1               17.7  ...   \n",
       "2                21.5                20.0               18.7  ...   \n",
       "3                16.2                19.2               18.6  ...   \n",
       "4                17.3                18.7               17.4  ...   \n",
       "\n",
       "   ENSG00000269699.4  ENSG00000269711.1  ENSG00000269741.4  ENSG00000269749.1  \\\n",
       "0                0.0                0.0                0.0                0.0   \n",
       "1               10.2               10.8                8.4               10.5   \n",
       "2                9.6                0.0                0.0                0.0   \n",
       "3                0.0                0.0               13.6                0.0   \n",
       "4                8.9                0.0                0.0                0.0   \n",
       "\n",
       "   ENSG00000269755.1  ENSG00000269846.1  ENSG00000269855.2  ENSG00000269858.4  \\\n",
       "0               11.9                9.4               11.5               16.7   \n",
       "1               10.2                7.9               13.9               16.2   \n",
       "2               10.6               10.9                0.0               16.5   \n",
       "3               10.1                8.9               13.8               15.8   \n",
       "4               11.6               10.6               11.5               18.6   \n",
       "\n",
       "   ENSG00000269881.1  ENSG00000269883.1  \n",
       "0               11.2                7.1  \n",
       "1                9.8                7.2  \n",
       "2                9.2                0.0  \n",
       "3               10.2                0.0  \n",
       "4               10.1               12.2  \n",
       "\n",
       "[5 rows x 19562 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace the original Type labels with the new labels predicted from our k-means model.\n",
    "labels = model.labels_\n",
    "tc_coding['Type'] = labels\n",
    "tc_coding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (4320, 19561, 1)\n",
      "X_test shape: (1080, 19561, 1)\n",
      "Y_train shape: (4320, 12)\n",
      "Y_test shape: (1080, 12)\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_8 (Conv1D)            (None, 19542, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 19542, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 3908, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 3899, 64)          41024     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 3899, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 389, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 24896)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 200)               4979400   \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 12)                0         \n",
      "=================================================================\n",
      "Total params: 5,026,040\n",
      "Trainable params: 5,026,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 2.4142 - accuracy: 0.1713 - auc_4: 0.6137 - val_loss: 2.3714 - val_accuracy: 0.2241 - val_auc_4: 0.6415\n",
      "Epoch 2/100\n",
      "135/135 [==============================] - 4s 28ms/step - loss: 2.3663 - accuracy: 0.2079 - auc_4: 0.6421 - val_loss: 2.3292 - val_accuracy: 0.2241 - val_auc_4: 0.6772\n",
      "Epoch 3/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.3166 - accuracy: 0.2123 - auc_4: 0.6760 - val_loss: 2.2648 - val_accuracy: 0.2241 - val_auc_4: 0.7206\n",
      "Epoch 4/100\n",
      "135/135 [==============================] - 4s 29ms/step - loss: 2.2191 - accuracy: 0.2387 - auc_4: 0.7289 - val_loss: 2.1585 - val_accuracy: 0.2778 - val_auc_4: 0.7853\n",
      "Epoch 5/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 2.0261 - accuracy: 0.3493 - auc_4: 0.7972 - val_loss: 1.8356 - val_accuracy: 0.4944 - val_auc_4: 0.8545\n",
      "Epoch 6/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.7152 - accuracy: 0.4822 - auc_4: 0.8681 - val_loss: 1.4291 - val_accuracy: 0.5806 - val_auc_4: 0.9338\n",
      "Epoch 7/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 1.3158 - accuracy: 0.5894 - auc_4: 0.9315 - val_loss: 1.0181 - val_accuracy: 0.7139 - val_auc_4: 0.9673\n",
      "Epoch 8/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.9380 - accuracy: 0.7340 - auc_4: 0.9681 - val_loss: 0.6674 - val_accuracy: 0.8944 - val_auc_4: 0.9875\n",
      "Epoch 9/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.6181 - accuracy: 0.8507 - auc_4: 0.9863 - val_loss: 0.3263 - val_accuracy: 0.9611 - val_auc_4: 0.9982\n",
      "Epoch 10/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.4020 - accuracy: 0.9083 - auc_4: 0.9937 - val_loss: 0.2056 - val_accuracy: 0.9667 - val_auc_4: 0.9986\n",
      "Epoch 11/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2873 - accuracy: 0.9338 - auc_4: 0.9964 - val_loss: 0.1345 - val_accuracy: 0.9731 - val_auc_4: 0.9996\n",
      "Epoch 12/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.2076 - accuracy: 0.9486 - auc_4: 0.9982 - val_loss: 0.1132 - val_accuracy: 0.9759 - val_auc_4: 0.9997\n",
      "Epoch 13/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1709 - accuracy: 0.9583 - auc_4: 0.9986 - val_loss: 0.0806 - val_accuracy: 0.9778 - val_auc_4: 0.9998\n",
      "Epoch 14/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1378 - accuracy: 0.9667 - auc_4: 0.9992 - val_loss: 0.0802 - val_accuracy: 0.9843 - val_auc_4: 0.9999\n",
      "Epoch 15/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.1187 - accuracy: 0.9692 - auc_4: 0.9993 - val_loss: 0.0917 - val_accuracy: 0.9806 - val_auc_4: 0.9992\n",
      "Epoch 16/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0966 - accuracy: 0.9773 - auc_4: 0.9996 - val_loss: 0.0683 - val_accuracy: 0.9843 - val_auc_4: 0.9998\n",
      "Epoch 17/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0945 - accuracy: 0.9752 - auc_4: 0.9995 - val_loss: 0.0470 - val_accuracy: 0.9852 - val_auc_4: 0.9999\n",
      "Epoch 18/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0797 - accuracy: 0.9801 - auc_4: 0.9998 - val_loss: 0.0630 - val_accuracy: 0.9778 - val_auc_4: 0.9994\n",
      "Epoch 19/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0702 - accuracy: 0.9833 - auc_4: 0.9997 - val_loss: 0.0419 - val_accuracy: 0.9880 - val_auc_4: 0.9999\n",
      "Epoch 20/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0604 - accuracy: 0.9840 - auc_4: 0.9999 - val_loss: 0.0752 - val_accuracy: 0.9769 - val_auc_4: 0.9993\n",
      "Epoch 21/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0502 - accuracy: 0.9854 - auc_4: 0.9999 - val_loss: 0.0509 - val_accuracy: 0.9852 - val_auc_4: 0.9999\n",
      "Epoch 22/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0523 - accuracy: 0.9861 - auc_4: 0.9998 - val_loss: 0.0404 - val_accuracy: 0.9870 - val_auc_4: 0.9995\n",
      "Epoch 23/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0489 - accuracy: 0.9891 - auc_4: 0.9999 - val_loss: 0.0456 - val_accuracy: 0.9861 - val_auc_4: 0.9995\n",
      "Epoch 24/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0428 - accuracy: 0.9896 - auc_4: 0.9999 - val_loss: 0.0338 - val_accuracy: 0.9880 - val_auc_4: 0.9999\n",
      "Epoch 25/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0378 - accuracy: 0.9919 - auc_4: 1.0000 - val_loss: 0.0486 - val_accuracy: 0.9852 - val_auc_4: 0.9990\n",
      "Epoch 26/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0336 - accuracy: 0.9921 - auc_4: 1.0000 - val_loss: 0.0359 - val_accuracy: 0.9889 - val_auc_4: 0.9999\n",
      "Epoch 27/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0328 - accuracy: 0.9917 - auc_4: 0.9999 - val_loss: 0.0381 - val_accuracy: 0.9907 - val_auc_4: 0.9999\n",
      "Epoch 28/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0298 - accuracy: 0.9926 - auc_4: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9852 - val_auc_4: 0.9995\n",
      "Epoch 29/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0280 - accuracy: 0.9933 - auc_4: 1.0000 - val_loss: 0.0429 - val_accuracy: 0.9880 - val_auc_4: 0.9990\n",
      "Epoch 30/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0237 - accuracy: 0.9949 - auc_4: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9898 - val_auc_4: 1.0000\n",
      "Epoch 31/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0261 - accuracy: 0.9931 - auc_4: 1.0000 - val_loss: 0.0280 - val_accuracy: 0.9889 - val_auc_4: 1.0000\n",
      "Epoch 32/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.0220 - accuracy: 0.9951 - auc_4: 1.0000 - val_loss: 0.0318 - val_accuracy: 0.9889 - val_auc_4: 0.9999\n",
      "Epoch 33/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0227 - accuracy: 0.9940 - auc_4: 1.0000 - val_loss: 0.0307 - val_accuracy: 0.9898 - val_auc_4: 0.9990\n",
      "Epoch 34/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0190 - accuracy: 0.9975 - auc_4: 1.0000 - val_loss: 0.0274 - val_accuracy: 0.9870 - val_auc_4: 1.0000\n",
      "Epoch 35/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0176 - accuracy: 0.9958 - auc_4: 1.0000 - val_loss: 0.0323 - val_accuracy: 0.9889 - val_auc_4: 1.0000\n",
      "Epoch 36/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0187 - accuracy: 0.9963 - auc_4: 1.0000 - val_loss: 0.0398 - val_accuracy: 0.9889 - val_auc_4: 0.9999\n",
      "Epoch 37/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0158 - accuracy: 0.9972 - auc_4: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9907 - val_auc_4: 1.0000\n",
      "Epoch 38/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0154 - accuracy: 0.9981 - auc_4: 1.0000 - val_loss: 0.0302 - val_accuracy: 0.9898 - val_auc_4: 1.0000\n",
      "Epoch 39/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0173 - accuracy: 0.9970 - auc_4: 1.0000 - val_loss: 0.0394 - val_accuracy: 0.9889 - val_auc_4: 0.9990\n",
      "Epoch 40/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0149 - accuracy: 0.9970 - auc_4: 1.0000 - val_loss: 0.0314 - val_accuracy: 0.9889 - val_auc_4: 1.0000\n",
      "Epoch 41/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0137 - accuracy: 0.9975 - auc_4: 1.0000 - val_loss: 0.0277 - val_accuracy: 0.9889 - val_auc_4: 1.0000\n",
      "Epoch 42/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0090 - accuracy: 0.9988 - auc_4: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9880 - val_auc_4: 0.9990\n",
      "Epoch 43/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0119 - accuracy: 0.9981 - auc_4: 1.0000 - val_loss: 0.0319 - val_accuracy: 0.9870 - val_auc_4: 0.9995\n",
      "Epoch 44/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0147 - accuracy: 0.9970 - auc_4: 1.0000 - val_loss: 0.0326 - val_accuracy: 0.9898 - val_auc_4: 1.0000\n",
      "Epoch 45/100\n",
      "135/135 [==============================] - 4s 31ms/step - loss: 0.0130 - accuracy: 0.9968 - auc_4: 1.0000 - val_loss: 0.0308 - val_accuracy: 0.9880 - val_auc_4: 0.9995\n",
      "Epoch 46/100\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0118 - accuracy: 0.9981 - auc_4: 1.0000 - val_loss: 0.0396 - val_accuracy: 0.9889 - val_auc_4: 0.9999\n",
      "Epoch 47/100\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9965 - auc_4: 1.0000Restoring model weights from the end of the best epoch.\n",
      "135/135 [==============================] - 4s 30ms/step - loss: 0.0140 - accuracy: 0.9965 - auc_4: 1.0000 - val_loss: 0.0322 - val_accuracy: 0.9889 - val_auc_4: 0.9990\n",
      "Epoch 00047: early stopping\n",
      "Test score: 0.038111455738544464\n",
      "Test accuracy: 0.9907407164573669\n",
      "Test AUC: 0.9999347925186157\n",
      "Test weighted F1 score: 0.9907646960107993\n",
      "Confusion Matrix:\n",
      " tf.Tensor(\n",
      "[[ 61   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0  60   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0 239   0   0   0   0   0   0   0   1   2]\n",
      " [  0   0   0  63   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 115   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0  55   0   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0 101   0   0   0   1   0]\n",
      " [  0   0   0   0   0   0   0  69   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  51   0   0   0]\n",
      " [  0   1   1   0   1   0   0   0   0 125   0   1]\n",
      " [  0   0   1   0   0   0   0   0   0   0  61   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  70]], shape=(12, 12), dtype=int32)\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# Train model with the TC data and new \"types\".\n",
    "EPOCH = 100\n",
    "BATCH = 32\n",
    "CLASSES = len(tc_coding.Type.unique())\n",
    "\n",
    "PL = 19562   # 1 + 60483 these are the width of the RNAseq datasets\n",
    "P     = 19561   # 60483\n",
    "DR    = 0.1 \n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load_data(tc_coding, CLASSES)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "\n",
    "print('Y_train shape:', Y_train.shape)\n",
    "print('Y_test shape:', Y_test.shape)\n",
    "\n",
    "model = build_model(CLASSES)\n",
    "model = train_model(model, X_train, Y_train, X_test, Y_test, 'q5')\n",
    "evaluate_model(model, X_test, Y_test)\n",
    "\n",
    "model.save_weights(\"q5.model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary: \n",
    "In order to determine my own types, I first visualized the data after transforming the `tc.coding.csv` data with UMAP. UMAP is a dimension reduction technique. We are able to see the data forms natural clusters. Based on this, I choose several k-values to try for k-means. I try values of `k=10,12,14,16,18,20` and I use an elbow plot of the sum of squared errors to determine the best k-value, which we find to be `k=12`. I performed k-means clustering with `k=12` and then use the cluster labels as the \"types\" for the classifier. With this new data, I train a classifier for the 12 \"types\". We achieve very high accuracy of 99.1%. This increase in accuracy after re-\"typing\" is expected since we chose types based on the natural clustering of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 6: Using any method you like, attempt to produce a model that can generate new data samples labelled as Normal and Tumor and run those newly generated samples through the classifier developed in Step 3.  Report on the results. \n",
    "\n",
    "For this problem, I use Gaussian Mixture models to describe the distribution of the `nt.coding.csv` data. GMMs have difficulty converging in high dimensional space (~19,000 features) so first I perform PCA, preserving 99% of the variance in the projected data. Then fit many GMM models with various values for the number of components. We choose the GMM model with low AIC (40 components). I can sample new data from this distribution and I label the samples using a kNN model (10 neighbors) fit with the `nt.coding.csv` data. Then I inverse transform the projected data so that we have the data back in the original space. With this new unseen labeled data, I compare the predictions of the classifier with the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1400, 66)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = nt_coding.iloc[:,1:]\n",
    "pca = PCA(0.99, whiten=True)\n",
    "data = pca.fit_transform(X)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure out how many GMM components to use.\n",
    "n_components = np.arange(1, 100, 10)\n",
    "models = [GMM(n, covariance_type='full', random_state=0)\n",
    "          for n in n_components]\n",
    "aics = [model.fit(data).aic(data) for model in models]\n",
    "plt.plot(n_components, aics);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above is done to determine the number of component in order to get the best distribution fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_data(X):\n",
    "    pca = PCA(0.99, whiten=True)\n",
    "    data = pca.fit_transform(X)\n",
    "    gmm = GMM(40, covariance_type='full', random_state=0)\n",
    "    gmm.fit(data)\n",
    "    all_new_data = gmm.sample(500)\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=20)\n",
    "    neigh.fit(data, nt_coding.Type)\n",
    "    labels = neigh.predict(all_new_data[0])\n",
    "    prob = neigh.predict_proba(all_new_data[0])\n",
    "    # print(prob)\n",
    "    idxs = np.where(prob==1)[0]\n",
    "    filtered_new_data = all_new_data[0][idxs]\n",
    "    filtered_new_labels = labels[idxs]\n",
    "    \n",
    "    return all_new_data, filtered_new_data, filtered_new_labels\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new, new_data, new_labels = get_new_data(nt_coding.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/d3fzzAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlwklEQVR4nO3df5xdVXnv8c8zMyfJhGgGkljMTGLCpY1KjEYGX9hQWwk2CiakVCNSf3IltWCxWIPBtiHmaknBK5Ba28ZIb71ScC7EAbQQFdp7Db0CEwMBoakWhMzEH0kgaTET5tfTP86c5MyZvc+vvc+Pfc73/Xrxmsyec9ZeJ2Ges86znrWWuTsiIpJcLbXugIiIRKNALiKScArkIiIJp0AuIpJwCuQiIgnXVoubzp492xcsWFCLW4uIJNauXbsOuvuc3Os1CeQLFiygr6+vFrcWEUksM3s26LpSKyIiCadALiKScArkIiIJF0uO3MyuAj4COPA48GF3PxZH2yIicRkeHqa/v59jx+o7PE2bNo2uri5SqVRRj48cyM2sE7gSeK27D5pZD3Ax8L+iti0iEqf+/n5e9rKXsWDBAsys1t0J5O4cOnSI/v5+Fi5cWNRz4kqttAHtZtYGTAf2x9SuiDSaPT1w42LY2JH+uqenarc+duwYs2bNqtsgDmBmzJo1q6RPDZEDubsPAJ8HngN+Chxx928HdG6tmfWZWd+BAwei3lZEkmhPD9xzJRzZB3j66z1XVjWY13MQzyi1j5EDuZmdDFwILATmAieZ2ftyH+fuW929292758yZVM8uIs3g/k0wPDjx2vBg+rqULY7UynnAM+5+wN2Hge3Ar8fQrog0miP9pV1vUPfddx+LFi3i9NNPZ/PmzZHbiyOQPwecbWbTLf15YDnwVAztikijmdlV2vUGNDo6yhVXXMG9997Lk08+yW233caTTz4Zqc04cuQPAXcAPyBdetgCbI3arog0oOUbINU+8VqqPX29DvXuHmDZ5gdYuP5bLNv8AL27ByK3+fDDD3P66adz2mmnMWXKFC6++GLuuuuuSG3GUkfu7tcC18bRlog0sCVr0l/v35ROp8zsSgfxzPU60rt7gGu2P87g8CgAA4cHuWb74wCsXtpZdrsDAwPMmzfv+PddXV089NBDkfpak02zRKSJLVlTl4E71w079h4P4hmDw6PcsGNvpEAedE5y1EoaLdEXEQmw//BgSdeL1dXVxb59+45/39/fz9y5cyO1qUAuIhJgbkd7SdeLddZZZ/GjH/2IZ555hqGhIW6//XZWrVoVqU0FchGRAOtWLKI91TrhWnuqlXUrFkVqt62tjS9+8YusWLGC17zmNaxZs4YzzjgjWpuRni0i0qAyefAbduxl/+FB5na0s27Fokj58Yzzzz+f888/P3I7GQrkIiIhVi/tjCVwV5pSKyIiCadALiKScArkIiIJp0AuIpJwCuQiIgmnQC7SiGp4Co8Udumll/KKV7yCxYsXx9KeArlIo6mDU3gkvw996EPcd999sbWnQC7SaHQKT3wq9MnmLW95C6ecckosbYEWBIk0Hp3CE4/MJ5vMm2Lmkw3U3e6NGpGLNBqdwhOPBH2yUSAXaTQJO4WnbiXok40CuUijWbIGVm6BmfMAS39duaXu0gF1L0GfbBTIRRrRkjVw1ROw8XD6q4J46Sr4yea9730vb37zm9m7dy9dXV185StfidReLJOdZtYBbAMWAw5c6u7/P462RURqooLni952222R28gWV9XKzcB97v4uM5sCTI+pXRGR2knI+aKRA7mZvRx4C/AhAHcfAoaitivSdPb0JOJ0eak/ceTITwMOAH9nZrvNbJuZnZT7IDNba2Z9ZtZ34MCBGG4r0kC0GrNqgk6xrzel9jGOQN4GvBH4a3dfCvwSWB/Qsa3u3u3u3XPmzInhtiINJEE1y0k2bdo0Dh06VNfB3N05dOgQ06ZNK/o5ceTI+4F+d39o/Ps7CAjkIpJHgmqWk6yrq4v+/n7qPSswbdo0urqKL3OMHMjd/Wdmts/MFrn7XmA58GTUdkWaysyu8bRKwHWJTSqVYuHChbXuRuziqiP/Q+BWM9sDvAH485jaFWkOWo0pEcRSfujujwLdcbQl0pQqWLMsjU+7H4rUi4TULEv90RJ9EZGEUyAXEUk4BXIRkYRTIBcRSTgFchGRhFMgFxFJOAVykVwVOjldpFJURy6S7ZufgL5bSJ+PQl2fnC6SoRG5SMaenolBPEO7EEqdUyAXybh/E5OCeIZ2IZQ6pkAukpEvWGsXQqljCuQiGaHB2rQLodQ1BXKRjKCtZDHovlQTnVLXVLUikqGtZCWhFMhFsmkrWUkgpVZERBJOgVxEJOEUyCXZtJxeJL4cuZm1An3AgLu/M652RULt6Ukvnx8eTH+v5fTSpOIckX8ceCrG9kTyu3/TiSCeoeX00oRiCeRm1gVcAGyLoz2RCcLSJ2ErMbWcXppMXKmVm4CrgZeFPcDM1gJrAebPnx/TbaXh7emB3sthbDj9/ZF96e8hXed9ZN/k52g5vTSZyCNyM3sn8At335Xvce6+1d273b17zpw5UW8rjS4zCt9+2YkgnjE2DPd+KnglZqpdy+ml6cSRWlkGrDKznwC3A+ea2ddiaFeaVWYSM2i0nTH4fPrryi0wcx5g6a8rt2iiU5qOuYds21lOY2a/BXyyUNVKd3e39/X1xXZfaTA3Ls4fxDNS7Qrc0lTMbJe7d+deVx251Ea++u9iJytVoSICxLzXirv/M/DPcbYpDahQ/XfYJGYQVaiIaEQuNVCo/jtwO9kQqlARUSCXGihU/71kzeRJzO7/rgoVkRDaxlZi0bt7gBt27GX/4UHmdrSzbsUiVi/tDH5wMfXfQdvJzj9be4WLBFAgl8h6dw9wzfbHGRweBWDg8CDXbH8cIDiYL98wMUcOxY2utVe4SCClViSyG3bsPR7EMwaHR7lhx97gJwSlTlRGKFI2jcilPHt64P5N+JF+vj42i+tb1nD32DkTHjJweDDkyWh0LRIjBXIp3Tc/AX23AI4BXS0H2ZzaBsNMCOatZjXrokgzUWpFSrOn53gQzzbdhri6beKhDqMxrhoWkXAK5FKa+zeRG8Qz5tqhCd93dhRZCy4ikSiQS2nyrKTc77OO/7k91cq6FYuq0SORpqccuUxQsB48pAZ8zOH6kfTkZUd7io2rzgivIxeRWCmQN6HsYP3BGQ9zderrTB/8GUfbT+X//udFDIwsA9JVJ+vueAzIqgcPqAEfA742eh67Xv42bsq3EEhEKiLWbWyLpW1sayd78c5n2m7h/a3fpSWruMQdXmAGG4c/cLwC5eTpKXZv+O0TDxovPdQKS5HqCtvGViPyhCtpaTwnFu98pu0WPtD6XXIrBM3gFF6cUE74wtGcE3pUAy5SVzTZmWCZ0fXA4UGcE0vje3cPhD5n/+FBVrXs5P0BQTxbUDmhiNQnjcgTLN/S+OxRefaovcWMq9t6JqRTwmTKCTvaU7H2W0TipUCeYPtDlsDvPzw4YQn9WT6LM4fXMMA5jLoz1w4W177PItVibFx1RpzdFpGYKZAn2NyO9sD9TD7f/lXYvoPMEvpOO8hNqS9xM19iwGfzgs9glr2Yt+2jPoVtU97HDb/zelWhiNS5yIHczOYBXwVOJV2JttXdb47aroTLpEoGDg9iTFxn+a4p/8JFft+k52RSKV12kCFv4yVvZaqdSMuMOQzaNE7iJZjZxfTlG9ioCU2RRIhjRD4C/LG7/8DMXgbsMrPvuPuTMbQtOXL3/nbAgJUtO/n0lP/Dr3CAQunvKTbC8z6DA2PTmGuH2O+zuImLOWf15Rp9iyRQ5EDu7j8Ffjr+5/80s6eATkCBvAKCJjhXtuxkc2ob0xkqup0OfsnK6f+76LJFEalfsebIzWwBsBR4KM525YSgCc6r23qYbsUHcYBf2GweXH9uXN0SkRqKLZCb2QzgTuCP3P0/An6+FlgLMH/+/Lhu23Q+OONhrhzexsmkJyuf9xmcUmDiMtegT2Hfmes4tRIdFJGqi2WJvpmlgG8CO9z9C4UeryX6xcmu/75u2t/zbr5Ni/ukhTzu5F3ck/24n9sc9r1xHWet+v3KdFpEKqZiS/TNzICvAE8VE8SlOLl7orzHx1diBgTsoCCeG9yHvJXHzryOs1b9vkbiIg0mjtTKMuD9wONm9uj4tU+7+z/G0HbTevRbW/mOfY25Uw9iFDfizvaiT+WIv4y5dohf2Gz2nalRuEijiqNqZSeB40Qp1SN3/y2n/2ATHf4i1wIWYSeck1qGuP/C/8fqpZ2cChqFizQwreysB3t6GN2+lu5M/juGt8WWmV0qJxRpEtr9sMb+6qbPMXbnZbQyeRKzGO4wlhv5U+3pPcJFpCloRF4FuXuGf/wVuznnuS/xSj/I5RSf/84tMPq5zUnnvhecrIMeRJqYAnmFZVefrGrZyfWDW5n67EjJKZSjPoX1wx/he9PeyrUrz5ic+1bgFmlaCuQV0Lt7gI13/5DDgydO1rl3yjpebQMlp0+yj147tHAVuy97c8y9FZGkUyCPQXbqpGN6iiNHhxkb/9mqlp1cn/oyUxkuK4h/dfQ8rh25lCmtxr8piItIAAXyiHJ3I3zh6DCrWnbyF21/y7TxbWLLmcSE9PL7a0cuJdViXP+u18fVZRFpMArkEeXuRvjV1Of4jZYflh28M476FDaNfIBO7UwoIgUokEeUvRthlDw4wDBGG3Bs+qlMf8cmbtYEpogUQYG8TL27BzjrG7/O01MPT7geJQ/enmrluotep9G3iJREgbwMf7bpz/jMyBbMys9/u6dP9/nEyOX0jp6jFIqIlE2BvAi9uwf4zD0/5DeO/RN/nrqFTRyLtA/KiLfw2dSVvOGCtdy0tJObYuupiDQjBfIc2aWEH5zxMOv877hw5AgXAqTKH4FnjLROo+3Cvyz/YOM9PVrFKSITKJBnyS4lvHfKOl49PBB5Eyv39JayM1qGsJldtAUF3mKD854euOdKGB6fYD2yL/09KJiLNLGmD+TZI/AWMy6w73Hj1C/RQrT8N6Rz4F8bPY+X/+6W8Nx3KcH5/k0nHpcxPJi+rkAu0rSaLpDnrsJ88dgIw2POqpadfCH1JVqJFsCHaeGTwx/l7rEiJzBLCc5H+oPbCLsuIk2hqQL5n/Y+zq3ff47MJoIvHB3mwSmXM9cOA9Hy35lR+EE7hfefvYAtqy4o7omlBOeZXekRe9B1EWlaTbMfee/ugQlB/Kupz/HM1EuYa4cjlRFmZNqYy0HOevzadMqkGGFBOOj68g3pvcazae9xkabXNIF8490/xIEfT7mEZ6ZecnwZfdQAHiiTGilGKcF5yRpYuQVmzgMs/XXlFuXH692eHrhxMWzsSH8t9k1epEixpFbM7O3AzUArsM3dN8fRblx6bvmf7B7bBFPT38cRvJ0CxSz58ta5VSqvvwR+9O3iSgqXrFHgTpIEVBrlHnyihWnJEzmQm1kr8FfA24B+4BEzu9vdn4zadmR7evA7L+PdxDvyLhjEITxlEvSL/dg/aGTdqPJMZveOLqt5AM3dvXPg8CDXbH8cQME8QeJIrbwJ+LG7P+3uQ8DtkF4/Uwu9uwf43oZl+LUz8Tsvi5w+cYcxh2OkjufXCzaXL2+dr0pFGk/IJzM/0s812x9n4PAgzokA2rt7oKrdy929E2BweJQbduytaj8kmjgCeSeQXUrRP35tAjNba2Z9ZtZ34MCBGG47Ue/uAfZuOIMLe1/LOfZELPlvd7jN38auM69nWqqtuHVBhfLWKiFsLiGfzH7O7LoIoNm7dxZzXepTHIE8KL75pAvuW929292758yZE8NtT/jRxnQA/zXrj20C04GnF1zMJZvu4Kx//8vJo+hcqXa46Mtw1RP5UySlVKlI8oVMZl839O7Ah1c7gM7taC/putSnOAJ5PzAv6/suYH8M7Ybq3T3Ass0P8NSG1+LXzuR0jx7A3U/sSEj7KdhFX+a/ffhv0z/MO1ousXpEJYSxy/z/sHD9t1i2+YGqpyfyCqk06nv52wIfXu0Aum7FItpTrROutadaWbdiUVX7IdHEUbXyCPCrZrYQGAAuBi6Jod1AvbsH2PmNL/E9+2Jso+/MCfXnvvtjwRM8oQtx5qVH4KXIBPtSN74qtB9Lk26mlYjJuoBKo3WjE/sNtQmgmb+jWk+6SjTmPikLUnojZucDN5EuP7zF3T+X7/Hd3d3e19dX+o329DC2/TLMY0qfjJ9QvyX1Ed5wwdri90OB9Ci6WpUmhe5f6/7V0LLNDzAQkI7o7GjnwfXn1qBHxVPZn5TKzHa5e/ek63EE8lKVFcj/x6kwGl/+cMRbWDf6B/zm715R3C9PLUe8Ny7O/4mg0M8b2ML135o8IUN64uaZzUVukyCSEGGBPBl7rVw3P9YgDtBiXnwQh8ILcSoZ6EMrXfal7xtXJUwC0zNzO9oDR+SarJNmkoxA/tKRsp6W+bARlIZpmdlVOIjXyz7hYTl6SN+n/WQYfD74ecXa0wN3XQGjQ+nvj+xLfw8FX0PcKYJS2lu3YlFd5JpFaqlh91pxh1GH530Gk7JHrVNg6Jf5977IBOcj+wA/EZyDHnvvp4IX+Xzjo/HsrxFU6ZJ9H4heCXPvp04E8YzRofT1PDKTjXEtbCm1vdVLO7nuotfR2dGOkc6N6wBraTbJGJGXyB32ewcn21Fm2YsTfzjlJBgZOjGCzR49w4kRuLWAT1ywEbhP+J6e4NEwnHh+1BF65jnbLwv++eALcNHWaGmRsNcQdn1cvpWB5QTTctpbvbRTgVuaWjIC+dSZgekVz/qDW/rrfp/N9SNruLqth+k2NOk5DB8LDtD3fgpGBk+McHMfk5Gbdy52aX3Uk3yWrBkP1CH7kddoM624VwZqpaE0qkpWKSUjtXLNc+lgnsNmvBLbeAT7zBFaNh5hw9Kd/MbQFu4eO4e5djC4rbAAPfh84dWbMDnvXMqEYtRl+JVcTNR+SmnXx8W9MlArDdPqepGTlCzuFGSuZIzIIR3MC/js6tfR/apT0u96R2fTFRTMrTU8mBcSFDTzTUTmiroMv5TFREETtfme+46/gN7LYWz4RBstqfT1POKebNTkZUIWOUlJ4k5B5kpOIC/S8XzpnuuCF8m8/pL0trG519vaC+SDLf3c3KC5fMPk+wSJa+RcTAolqIrmrivGt3IcPnEtO29f5orTuFcGaqVh5X/ppfoqnTJsuEB+XL7ANP/s4NFq3oDs6cMfIM/BEHlG5gGrLLNzZh+c8TBXp77O9MGfRa/hDtoqN7ciBSbn7cvMs8c92djsk5eaJ2g8lV7v0LiBHMIDU76AFTahCOnAne9giNDJyHmBQTzz8XlVy06uHt7G9JGsGu7ey9MTsIMvlB7Yq5m3l9hpkVPjqXTKMBmTndWyZE16SfvMecE/n9kVfjDENz4Kv/rbRU9GZn98DqywGRseT/UUqGEP0n5ycY8DbZ9bh7QjYeOp9HqHxh6Rlyso750JyNvXBj/HR9Mj8yLP38z+mBxaYZMtavlikAptn6vNoKLRPEFjqmTKUIE8SL78er7Uy/BgOogXsVFV9sfn/R5SYZOr2DTI4AuhPzra/kqmDf6M/WOz2Obv4w2jy1hdXKtFSVLFRZQ3nEq/WTX7PIGURoE8TFgevVCVypF96SX5BXLa2Tmz60fW8PnUVqbYSP4+FZsGCSmJPNr+Ss588aYTebohaI85yBZTcVEPI/Yobzj18GZVD3+HUj+UI8+1pycdiMP2SMmc+GKtgU8HisppZ+fMulv+jbZCQbyUNEjIwqHrh99T8XMiC1VcVHphRLGiHDpc6wOL6+XvUOqHAnm2YjfKWrIGzvwQwceVjsvktPNYvbSTB88/yAfa7g/+h7BWSj5KLtO/gOPF/v7FNwU+PM6ytkIrM6sdBMNWSEYp8at1eWCt30ik/ii1ki2sIiVoo6zH/oGAM6YnOrIvPbLPVz54/6bwdnwMNh4uvv/ZAlJDc/8x+DSdOMvagsqsAI4OjdC7e6CqQTBfCiRKiV+tywNr/UYi9Ucj8mzFHtAQFPBDFSgfzDeBGUNpYPaI9JcvjZBqNVa17GTnlCt5euolPDj1Sm567Y8i3ycjkzLqaE9NuP7C0WGu2f44M3OuZ1QiCOYbuUYp8at1eWDY31WLmfZmaVIakWcLPWQ5wkZZGWHlg6F7tVjk0sBJi45Ge5jbdhDsxDt4JwfpfOxP4anN5S0+CrB6aSc37NjL4cHhCdcHh0eZlmqhPdUa68KIsIm/fCPXKCV+tSwP7N09wNGh4PmU0fGN9+u5UkgqI1IgN7MbgJXAEPDvwIfd/XAM/aqNfPXj2cKCr7Wm0yFhqZKgN4DAKhiD7ksj14xnRqSrWnayObUteFtfSC/fD9qfPcL9w4Lo4aPD3PieN8QWBMtJn7SY0bt7IFKJXy3KA3Nfa8b4Ds4TaG+W5hI1tfIdYLG7LwH+DbgmepdqKGSSMHCjrKAVnL/zN+mcdr6VocXc86Kt8M4vRH45mWAaujd7mCImagvJN+m5emknD64/l2c2X8CD68+NFGxKTZ9AeuSaxCqPoNcK4TM1ypk3j0gjcnf/dta33wfeFa07daCYjaMK7RRY7Mi+lHuWITMiLWrlaK6Ie7BUazvaYtInf9zz2PG0Q0YSR6ylBmbtzdI84pzsvBS4N+yHZrbWzPrMrO/AgQMx3rZGlqxJB+aZXemgd/+mE5OZxY7sK2zdikW8a8q/MFbOP3PEidZqnaVZqNxx9dJOxiYd2pqWGxjr/TCHsNd68vSU9mZpcgV/w83su2b2RMB/F2Y95k+AEeDWsHbcfau7d7t795w5c+LpfS0VqjnPF+grICgIrW59kM2pbbTZ2KTHj3l6e/LnfUb6AIlsMe3BsnppJ+tWLGJuRzv7Dw9yw469sQfHYipIijl1KAmLbMJe67Urz9AB1E3OPGS0UnQDZh8EPgosd/ejxTynu7vb+/r6It235m5cHL5l7fIN41vQ5hxUkWqvyMg8aBKsPdXKrhl/xPTBn056/Ii38Inhj3L32Dl0drTz4PkHox3cnNWP7EnMt756DnfuGpjUr7iDTKHl6mF/P9n9WLY5uMa+s6OdB9efG1tfi+lvpZ4ryWdmu9y9e9L1KIHczN4OfAH4TXcvOl/SEIF8Yweh00yp9vA685nzitpUqxS5QWhVy06ubuuhs+Vg4NrTMTdOe+nWWINqULAMqqaAycGxGsEp6B5wooQw7LfAgGc2XxBrPwq9qYiECQvkUevIvwhMBb5jZgDfd/ePRmwzGfKVIOZbLFSBgxz25wTxvKWGwH6fRWfMATOooqKYaopqbUCVWy4YVsqXK+4JQx3jJpUQtWrl9Lg6kjhhlSmFVnyGTSIGHZZcZHoju166YKlhqp2uldfx4JJ40wWlVFRkB8daBbawUr5s1a6yESmXluiXK6wyJayGHMInEQtNnBbYkTF7EixvqWEx1TMh9ypU0RE2cs1N7eQGx3yBrZJVJPkCZy2rbETKoSX6UYTVfwftV95+CrzjLyZvvhV2UEX2opzcM0KzVl5mcr+Dw6O0moUfUpGVmw/NSQedR3rPlTzykxe45pFXBaY/ID26DZoobE+18rtndvJP/3ogNP8dtvqyY3qqoimXsPtWYnIzW7Xq66W5RK5aKUdDTHbmU0yaJDdoBrI8+7/Mo/e3dkwKCu+a8i/pksPRYycem1Utk3ey7Z9XBN7rZ8zh7GM3T7re0Z7ipZGxwBSFAb939nw+u/p1x6+FTTgG9WdqW8ukvVogvkBby0lHVZ5IuSpStVKuhg/kxQgrX8w2c9745GjQv5GxbNr2wFHlh2Y8zMaT7gx8I8lbZnfsosB7ZapcSpUddPMFTpi8AdVVX3805FVPriIpNzAqoErSVKpqRcpVqHolk08PS73M7GL/z4NH83//4pvY+KefCfxZ3sm2Xwke/f/CZufva4jse+Wb1AzabyUsXZObS45S9aJzMaVRaLKzVvItgc+elAzboGv5hrImzvI+J+Re+964LnBF4cnTg/cWz8jsMgilV2sUu+e3TssRUSCvnbAAfdGX05OSmZx6nn1byjngIO9zQu511qrfD1wCfu3KMwJ3F8zI3mWw1DedYvdqUTmfiHLktRWhdjyjnDxvnLnhTFtBaZCMzOKjSkwulrK0XjlxSTpNdkrFLVz/rbwTlJUIpMVWn2hpvDQCTXZKxRU6lLjcycV8bwDFHrumpfHSyBTIJTaVWOxSTFVKMW8QyqVLI9Nkp8SmEodJxFWVUi9L4+v98ApJJo3IJVa5qY5MwC03mBczki4m914PS+OrtdOjNB+NyCVWcZ+0U2gkXez9qnX0XD6qeZdK0YhcYlUoWJVatVJoJF3KJGatV3IqTy+VokAusZYFhgWlzEi51LRCoaqUJAXHQlU9IuVSIG9ycedtw4JVq1nZ5X/5RtKVCI6VWjhUD3l6aUzKkTe5uPO2YVsAjIYsPIs6ci5nm4J84s7xZ6uHPL00Jo3Im1zcqYmwVEixuxkWI3fEXOjwilJUeuFQrfP00phiCeRm9kngBmCOu+c5a0zqTSVSE2HBKo60QlAq6M5dAxNGtpla7XICe5Jy7iIZkVMrZjYPeBvwXPTuSLXFnZoIE1daoVAqqNjUSNjCnHpZOCRSijhG5DcCVwN3xdCWVFmxe5XEda+o7RYaMReTGsk3wasJSUmiSIHczFYBA+7+mFnueemTHrsWWAswf/78KLeVmCUpb1soFVRMaqTQaUWZx2i7W0mKgoHczL4LnBrwoz8BPg38djE3cvetwFZIb2NbQh8lqhj2Pa8XhUbMxeT8CwX7JL2xiUAROXJ3P8/dF+f+BzwNLAQeM7OfAF3AD8wsKOhLrezpgXuuHD+L0+HIPga3f4yPf/qaRG7aVCjXXkzOX3lwaTSxHSwxHsy7i6la0cESVXTj4sADlfvHZnPO0BYM+L2z5/PZ1a8rq/l6PHWnUJ90yIQklQ6WaFZH+gMvz7VDADhw6/efo/tVp5QcxKq1m1+pbxaFUiPVnOAVqYbYArm7L4irLYnRzK7AEfl+n3X8zw5lLXipxqk7QW8WV339Ufqefb7sTxGgPLg0Fi3Rb3TLN0BqYu73qE/h+pGJk53lLHipxuKZoDeLzKeIpOX3RSpFgbzRLVkDK7fAzHk4Rv/YbNYPf4S7x86Z8LByJvqqMWkY9qaQ+RRRiE7kkWagQN4MlqyBq57ANh7mb97Yyz05QbzcBS/VWBWa702h0Mi/khtgidQTBfIm89nVr+PG97whlh34qrGb37oViwhbalZo5K8TeaRZqGqlCcU50VfpScPVSzvpe/Z5bv3+c2QXyhYz8tcGWNIsNCKXulfupwgt/JFmoRG5JEI5I39tgCXNQoFcGpYW/kizUCCXhqaFP9IMlCMXEUk4BXIRkYRTakUkgnrc/VGajwK5SJmqtfujSCFKrYiUSStHpV5oRC4NpZqpDq0clXqhEbk0jGpvkqWVo1IvFMilYVQ71VGN3R9FiqHUijSMaqc6tHJU6kXkQG5mfwh8DBgBvuXuV0fulUgZ5na0MxAQtCuZ6tDKUakHkVIrZvZW4EJgibufAXw+ll6JlEGpDmlWUUfkfwBsdveXANz9F9G7JFKeUlMdWswjjcLcvfCjwp5s9ihwF/B24BjwSXd/JOSxa4G1APPnzz/z2WefLfu+IlHlLuaB9Og97hOOROJkZrvcvTv3esHUipl918yeCPjvQtIj+pOBs4F1QI+ZBZ7M5e5b3b3b3bvnzJkT8eWIRKPFPNJICqZW3P28sJ+Z2R8A2z09rH/YzMaA2cCB+LooEj8t5pFGErWOvBc4F8DMfg2YAhyM2KZIxYVVssxsT1W5JyLRRQ3ktwCnmdkTwO3ABz1K0l2kStatWESqZXIW8JdDIxVbCSpSKZECubsPufv73H2xu7/R3R+Iq2MilbR6aSczpk3OLA6PuvLkkjhaoi9N6/DR4cDrypNL0iiQS9PSplfSKBTIpWlpJag0Cm2aJU1Lm15Jo1Agl6amTa+kESi1IiKScArkIiIJp0AuIpJwCuQiIgmnQC4iknCR9iMv+6ZmB4AkbEg+m+beBEyvv3lffzO/dqjf1/8qd5+0D3hNAnlSmFlf0CbuzUKvv3lffzO/dkje61dqRUQk4RTIRUQSToE8v6217kCN6fU3r2Z+7ZCw168cuYhIwmlELiKScArkIiIJp0AewszebmZ7zezHZra+1v2pJjObZ2b/ZGZPmdkPzezjte5TtZlZq5ntNrNv1rov1WZmHWZ2h5n96/j/A2+udZ+qxcyuGv9//gkzu83MptW6T8VQIA9gZq3AXwHvAF4LvNfMXlvbXlXVCPDH7v4a4GzgiiZ7/QAfB56qdSdq5GbgPnd/NfB6muTvwcw6gSuBbndfDLQCF9e2V8VRIA/2JuDH7v60uw8BtwMX1rhPVePuP3X3H4z/+T9J/yI3zabdZtYFXABsq3Vfqs3MXg68BfgKHD9g/XBNO1VdbUC7mbUB04H9Ne5PURTIg3UC+7K+76eJAlk2M1sALAUeqnFXqukm4GpgrMb9qIXTgAPA342nlraZ2Um17lQ1uPsA8HngOeCnwBF3/3Zte1UcBfJgFnCt6eo0zWwGcCfwR+7+H7XuTzWY2TuBX7j7rlr3pUbagDcCf+3uS4FfAk0xR2RmJ5P+5L0QmAucZGbvq22viqNAHqwfmJf1fRcJ+YgVFzNLkQ7it7r79lr3p4qWAavM7CekU2rnmtnXatulquoH+t098wnsDtKBvRmcBzzj7gfcfRjYDvx6jftUFAXyYI8Av2pmC81sCukJj7tr3KeqMTMjnSN9yt2/UOv+VJO7X+PuXe6+gPS/+wPunohRWRzc/WfAPjNbNH5pOfBkDbtUTc8BZ5vZ9PHfgeUkZKJXhy8HcPcRM/sYsIP0zPUt7v7DGnermpYB7wceN7NHx6992t3/sXZdkir6Q+DW8UHM08CHa9yfqnD3h8zsDuAHpCu3dpOQpfpaoi8iknBKrYiIJJwCuYhIwimQi4gknAK5iEjCKZCLiCScArmISMIpkIuIJNx/AYsUry8z4D/oAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scatter_x = data[:,0]\n",
    "scatter_y = data[:,1]\n",
    "group = nt_coding.Type\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(scatter_x[ix], scatter_y[ix],label = g)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the original PCA projected data that we use to fit the GMM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "scatter_x = new_data[:,0]\n",
    "scatter_y = new_data[:,1]\n",
    "group = new_labels\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for g in np.unique(group):\n",
    "    ix = np.where(group == g)\n",
    "    ax.scatter(scatter_x[ix], scatter_y[ix],label = g)\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is the new projected data sampled from the fit GMM model. We only keep the new data with labels that the kNN models predicted with high confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_10 (Conv1D)           (None, 19542, 64)         1344      \n",
      "_________________________________________________________________\n",
      "activation_25 (Activation)   (None, 19542, 64)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_10 (MaxPooling (None, 3908, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_11 (Conv1D)           (None, 3899, 64)          41024     \n",
      "_________________________________________________________________\n",
      "activation_26 (Activation)   (None, 3899, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_11 (MaxPooling (None, 389, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 24896)             0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 200)               4979400   \n",
      "_________________________________________________________________\n",
      "activation_27 (Activation)   (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                4020      \n",
      "_________________________________________________________________\n",
      "activation_28 (Activation)   (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 37)                777       \n",
      "_________________________________________________________________\n",
      "activation_29 (Activation)   (None, 37)                0         \n",
      "=================================================================\n",
      "Total params: 5,026,565\n",
      "Trainable params: 5,026,565\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model = tf.keras.models.load_model('q2.model.h5')\n",
    "new_data = pca.inverse_transform(new_data)\n",
    "new_s = scale_data(new_data)\n",
    "new = np.expand_dims(new_s, axis=2)\n",
    "\n",
    "model = build_model(37)\n",
    "model.load_weights('q2.model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# evaluate_model(model, new, l)\n",
    "# model.predict(new)\n",
    "ypred = np.argmax(model.predict(new), axis=-1)\n",
    "ypred = np.where(ypred==36, 0, 1)\n",
    "ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9290322580645162\n",
      "F1 score: 0.9290972549556771\n",
      "Confusion matrix:\n",
      " [[73 11]\n",
      " [ 0 71]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "print(f'Accuracy: {accuracy_score(new_labels,ypred)}')\n",
    "print(f\"F1 score: {f1_score(new_labels,ypred, average='weighted')}\")\n",
    "print(f'Confusion matrix:\\n {confusion_matrix(new_labels,ypred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "The model predicted the classes of the new data with fairly high accuracy (92.9%). We can observe the number of TP, TN, FP, FN in the confusion matrix. We see that the model predicted all the normal samples correctly and incorrectly predicted 11 of the 82 tumor samples. This may be due to the fact that there could be more heterogeneity in the tumor group since it is comprised of many different types of tumors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-py38] *",
   "language": "python",
   "name": "conda-env-.conda-py38-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
